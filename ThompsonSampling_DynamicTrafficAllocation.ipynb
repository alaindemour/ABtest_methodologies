{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thompson Sampling: From Bayesian Posteriors to Optimal Traffic Allocation\n",
    "\n",
    "## Executive Summary\n",
    "\n",
    "This notebook shows how **Bayesian posterior distributions naturally lead to Thompson sampling** ‚Äî an elegant algorithm for dynamic traffic allocation in A/B/C testing.\n",
    "\n",
    "### The Problem\n",
    "\n",
    "Traditional A/B testing requires:\n",
    "- **Fixed traffic allocation** (e.g., 25% A, 25% B, 25% C, 25% control)\n",
    "- **Wait for statistical significance** before making decisions\n",
    "- **Waste traffic on inferior variants** while collecting data\n",
    "- **Cannot add/remove variants dynamically** without restarting the test\n",
    "\n",
    "### Thompson Sampling Solution\n",
    "\n",
    "Thompson sampling provides:\n",
    "- ‚úÖ **Dynamic traffic allocation** ‚Äî better variants automatically get more traffic\n",
    "- ‚úÖ **Minimized regret** ‚Äî less wasted traffic on poor variants\n",
    "- ‚úÖ **Natural exploration/exploitation** ‚Äî balances learning vs. optimizing\n",
    "- ‚úÖ **Add variants anytime** ‚Äî new variants seamlessly enter the competition\n",
    "- ‚úÖ **Bad variants fade out** ‚Äî poor performers naturally get less traffic\n",
    "- ‚úÖ **Mathematically optimal** ‚Äî provably minimizes cumulative regret\n",
    "\n",
    "### The Algorithm (Incredibly Simple)\n",
    "\n",
    "For each incoming user:\n",
    "\n",
    "1. **Sample** once from each variant's posterior distribution\n",
    "2. **Choose** the variant with the highest sampled value\n",
    "3. **Show** that variant to the user\n",
    "4. **Observe** the outcome (conversion/no conversion)\n",
    "5. **Update** that variant's posterior distribution\n",
    "6. **Repeat**\n",
    "\n",
    "That's it! No complex formulas, no stopping rules, no power calculations.\n",
    "\n",
    "### Real-World Performance\n",
    "\n",
    "With our passkey experiment data, Thompson sampling would have:\n",
    "- Automatically allocated **~70% of traffic to variant A** (the best performer)\n",
    "- Given **<5% traffic to variant B** (worst performer) after ~1000 users\n",
    "- Identified the winner **3-5x faster** than fixed allocation\n",
    "- **Converted more users** overall by routing traffic to better variants\n",
    "\n",
    "### Why It Works\n",
    "\n",
    "Thompson sampling elegantly solves the **exploration-exploitation tradeoff**:\n",
    "\n",
    "- **Early on**: Wide posteriors ‚Üí high variance in samples ‚Üí more exploration\n",
    "- **Later**: Narrow posteriors ‚Üí low variance in samples ‚Üí exploitation of best variant\n",
    "- **Automatically**: No parameters to tune, no decisions to make\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Multi-Armed Bandit Problem\n",
    "\n",
    "### The Metaphor\n",
    "\n",
    "Imagine you're in a casino with **K slot machines** (\"one-armed bandits\"):\n",
    "- Each machine has an **unknown probability** of paying out\n",
    "- You have a **limited budget** (number of pulls)\n",
    "- Goal: **maximize total payout**\n",
    "\n",
    "The dilemma:\n",
    "- **Exploration**: Try different machines to learn which is best\n",
    "- **Exploitation**: Play the machine you currently think is best\n",
    "\n",
    "Too much exploration ‚Üí waste plays on bad machines  \n",
    "Too much exploitation ‚Üí might miss a better machine\n",
    "\n",
    "---\n",
    "\n",
    "### A/B Testing is a Bandit Problem\n",
    "\n",
    "In A/B testing:\n",
    "- **\"Arms\"** = variants (A, B, C, control)\n",
    "- **\"Pull\"** = showing a variant to a user\n",
    "- **\"Payout\"** = user converts (1) or abandons (0)\n",
    "- **\"Unknown probability\"** = true conversion rate of each variant\n",
    "- **\"Limited budget\"** = finite number of users\n",
    "\n",
    "**Goal**: Maximize total conversions (not just identify the best variant)\n",
    "\n",
    "**Regret**: The difference between:\n",
    "- What we would have achieved if we always showed the best variant\n",
    "- What we actually achieved\n",
    "\n",
    "Thompson sampling **minimizes cumulative regret** ‚Äî it's provably optimal in the long run.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From Bayesian Posteriors to Thompson Sampling\n",
    "\n",
    "### The Natural Connection\n",
    "\n",
    "We've already learned that for conversion testing:\n",
    "\n",
    "- Each variant has a **true conversion rate** $p_i$ (unknown)\n",
    "- We model our **belief** about $p_i$ with a **Beta distribution**\n",
    "- After observing data, we update the Beta distribution using **Bayes' theorem**\n",
    "\n",
    "For variant $i$:\n",
    "$$\n",
    "p_i \\sim \\mathrm{Beta}(\\alpha_i, \\beta_i)\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $\\alpha_i = \\text{(prior successes)} + \\text{(observed conversions)}$\n",
    "- $\\beta_i = \\text{(prior failures)} + \\text{(observed non-conversions)}$\n",
    "\n",
    "---\n",
    "\n",
    "### The Thompson Sampling Insight\n",
    "\n",
    "**Key idea**: The posterior distribution **already represents our uncertainty** about which variant is best.\n",
    "\n",
    "If we **sample** from each posterior:\n",
    "- The best variant will usually have the highest sample\n",
    "- But sometimes a worse variant will sample higher (due to uncertainty)\n",
    "- This **naturally balances exploration and exploitation**\n",
    "\n",
    "**Probability matching**: Thompson sampling allocates traffic to variant $i$ proportionally to:\n",
    "$$\n",
    "P(\\text{variant } i \\text{ is best} \\mid \\text{data})\n",
    "$$\n",
    "\n",
    "This is **exactly** what we computed in the Bayesian approach (see ABmethodologies.ipynb)!\n",
    "\n",
    "---\n",
    "\n",
    "### Why Sampling Works\n",
    "\n",
    "Consider two variants:\n",
    "- **Variant A**: Beta(100, 50) ‚Üí mean = 0.67, narrow distribution (high certainty)\n",
    "- **Variant B**: Beta(10, 5) ‚Üí mean = 0.67, wide distribution (low certainty)\n",
    "\n",
    "If we sample from each:\n",
    "- **A's samples** will cluster tightly around 0.67\n",
    "- **B's samples** will vary widely around 0.67\n",
    "- Sometimes B will sample higher ‚Üí **exploration**\n",
    "- Usually A will sample higher (it's more certain) ‚Üí **exploitation**\n",
    "\n",
    "The algorithm **automatically** reduces exploration as we gain confidence.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thompson Sampling Algorithm\n",
    "\n",
    "### Initialization\n",
    "\n",
    "For each variant $i \\in \\{A, B, C, \\ldots\\}$:\n",
    "\n",
    "1. Choose a **prior** Beta distribution:\n",
    "   - **Non-informative**: Beta(1, 1) ‚Äî uniform prior\n",
    "   - **Weakly informative**: Beta($\\alpha_0$, $\\beta_0$) ‚Äî centered on expected conversion rate\n",
    "\n",
    "$$\n",
    "p_i \\sim \\mathrm{Beta}(\\alpha_i, \\beta_i)\n",
    "$$\n",
    "\n",
    "Initially: $\\alpha_i = \\alpha_0$, $\\beta_i = \\beta_0$\n",
    "\n",
    "---\n",
    "\n",
    "### The Loop (for each user)\n",
    "\n",
    "**Step 1: Sample from each posterior**\n",
    "\n",
    "For each variant $i$:\n",
    "$$\n",
    "\\theta_i \\sim \\mathrm{Beta}(\\alpha_i, \\beta_i)\n",
    "$$\n",
    "\n",
    "This gives us a **random sample** of what the conversion rate might be.\n",
    "\n",
    "---\n",
    "\n",
    "**Step 2: Choose the best sample**\n",
    "\n",
    "$$\n",
    "i^* = \\arg\\max_i \\theta_i\n",
    "$$\n",
    "\n",
    "Show variant $i^*$ to the user.\n",
    "\n",
    "---\n",
    "\n",
    "**Step 3: Observe outcome**\n",
    "\n",
    "$$\n",
    "r \\in \\{0, 1\\}\n",
    "$$\n",
    "\n",
    "where $r=1$ means conversion, $r=0$ means no conversion.\n",
    "\n",
    "---\n",
    "\n",
    "**Step 4: Update posterior**\n",
    "\n",
    "For the chosen variant $i^*$:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\alpha_{i^*} &\\leftarrow \\alpha_{i^*} + r \\\\\n",
    "\\beta_{i^*} &\\leftarrow \\beta_{i^*} + (1 - r)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "**That's it!** Repeat for the next user.\n",
    "\n",
    "---\n",
    "\n",
    "### Pseudocode\n",
    "\n",
    "```python\n",
    "# Initialize\n",
    "for variant in variants:\n",
    "    alpha[variant] = 1  # or use informative prior\n",
    "    beta[variant] = 1\n",
    "\n",
    "# For each user\n",
    "while True:\n",
    "    # Sample from each posterior\n",
    "    samples = {}\n",
    "    for variant in variants:\n",
    "        samples[variant] = sample_beta(alpha[variant], beta[variant])\n",
    "    \n",
    "    # Choose best sample\n",
    "    chosen = max(samples, key=samples.get)\n",
    "    \n",
    "    # Show variant, observe outcome\n",
    "    conversion = show_variant_to_user(chosen)\n",
    "    \n",
    "    # Update posterior\n",
    "    alpha[chosen] += conversion\n",
    "    beta[chosen] += (1 - conversion)\n",
    "```\n",
    "\n",
    "**5 lines of logic** ‚Äî simpler than any classical statistical test!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import beta as beta_dist\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation: Thompson Sampling in Action\n",
    "\n",
    "Let's simulate Thompson sampling with our passkey experiment's **true** conversion rates:\n",
    "\n",
    "- **Variant A**: 70.2% conversion (best)\n",
    "- **Variant B**: 68.2% conversion (worst)\n",
    "- **Variant C**: 69.0% conversion (middle)\n",
    "\n",
    "We'll compare:\n",
    "1. **Fixed allocation**: 33.3% traffic to each variant\n",
    "2. **Thompson sampling**: Dynamic allocation\n",
    "\n",
    "And measure:\n",
    "- How quickly each identifies the winner\n",
    "- Total conversions achieved\n",
    "- Traffic allocation over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True conversion rates (from real experiment)\n",
    "true_rates = {\n",
    "    'A': 3244 / 4625,  # 0.7016\n",
    "    'B': 1433 / 2100,  # 0.6824\n",
    "    'C': 1396 / 2022,  # 0.6903\n",
    "}\n",
    "\n",
    "print(\"True conversion rates (unknown to algorithm):\")\n",
    "for variant, rate in true_rates.items():\n",
    "    print(f\"  Variant {variant}: {rate:.4f} ({rate*100:.2f}%)\")\n",
    "\n",
    "# Best variant\n",
    "best_variant = max(true_rates, key=true_rates.get)\n",
    "best_rate = true_rates[best_variant]\n",
    "print(f\"\\nBest variant: {best_variant} ({best_rate*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def thompson_sampling(true_rates, n_users, prior_alpha=1, prior_beta=1, verbose=False):\n",
    "    \"\"\"\n",
    "    Simulate Thompson sampling for traffic allocation.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    true_rates : dict\n",
    "        True conversion rates for each variant (unknown to algorithm)\n",
    "    n_users : int\n",
    "        Number of users to simulate\n",
    "    prior_alpha : float\n",
    "        Prior successes (Beta alpha parameter)\n",
    "    prior_beta : float\n",
    "        Prior failures (Beta beta parameter)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict with simulation results\n",
    "    \"\"\"\n",
    "    variants = list(true_rates.keys())\n",
    "    \n",
    "    # Initialize posteriors\n",
    "    alpha = {v: prior_alpha for v in variants}\n",
    "    beta = {v: prior_beta for v in variants}\n",
    "    \n",
    "    # Track metrics\n",
    "    n_shown = {v: 0 for v in variants}\n",
    "    n_converted = {v: 0 for v in variants}\n",
    "    total_conversions = 0\n",
    "    \n",
    "    # Track history for visualization\n",
    "    history = {\n",
    "        'user': [],\n",
    "        'variant_chosen': [],\n",
    "        'converted': [],\n",
    "        'prob_A_best': [],\n",
    "        'prob_B_best': [],\n",
    "        'prob_C_best': [],\n",
    "    }\n",
    "    \n",
    "    # Simulate each user\n",
    "    for user_id in range(n_users):\n",
    "        # Step 1: Sample from each posterior\n",
    "        samples = {}\n",
    "        for v in variants:\n",
    "            samples[v] = np.random.beta(alpha[v], beta[v])\n",
    "        \n",
    "        # Step 2: Choose variant with highest sample\n",
    "        chosen = max(samples, key=samples.get)\n",
    "        \n",
    "        # Step 3: Simulate user outcome based on true rate\n",
    "        converted = np.random.random() < true_rates[chosen]\n",
    "        \n",
    "        # Step 4: Update posterior\n",
    "        alpha[chosen] += converted\n",
    "        beta[chosen] += (1 - converted)\n",
    "        \n",
    "        # Track metrics\n",
    "        n_shown[chosen] += 1\n",
    "        n_converted[chosen] += converted\n",
    "        total_conversions += converted\n",
    "        \n",
    "        # Compute P(each variant is best) via Monte Carlo\n",
    "        if user_id % 50 == 0:  # Every 50 users\n",
    "            mc_samples = 10000\n",
    "            best_counts = {v: 0 for v in variants}\n",
    "            for _ in range(mc_samples):\n",
    "                mc_samples_dict = {v: np.random.beta(alpha[v], beta[v]) for v in variants}\n",
    "                best = max(mc_samples_dict, key=mc_samples_dict.get)\n",
    "                best_counts[best] += 1\n",
    "            \n",
    "            prob_best = {v: best_counts[v] / mc_samples for v in variants}\n",
    "            \n",
    "            history['user'].append(user_id)\n",
    "            history['variant_chosen'].append(chosen)\n",
    "            history['converted'].append(converted)\n",
    "            history['prob_A_best'].append(prob_best.get('A', 0))\n",
    "            history['prob_B_best'].append(prob_best.get('B', 0))\n",
    "            history['prob_C_best'].append(prob_best.get('C', 0))\n",
    "        \n",
    "        if verbose and user_id % 500 == 0:\n",
    "            print(f\"User {user_id}: Chose {chosen}, Converted: {converted}\")\n",
    "            print(f\"  Traffic allocation: \", end=\"\")\n",
    "            for v in variants:\n",
    "                pct = 100 * n_shown[v] / (user_id + 1)\n",
    "                print(f\"{v}={pct:.1f}% \", end=\"\")\n",
    "            print()\n",
    "    \n",
    "    return {\n",
    "        'n_shown': n_shown,\n",
    "        'n_converted': n_converted,\n",
    "        'total_conversions': total_conversions,\n",
    "        'alpha': alpha,\n",
    "        'beta': beta,\n",
    "        'history': history\n",
    "    }\n",
    "\n",
    "print(\"Thompson sampling function defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Thompson sampling simulation\n",
    "n_users = 5000\n",
    "print(f\"Simulating Thompson sampling with {n_users:,} users...\\n\")\n",
    "\n",
    "results_ts = thompson_sampling(true_rates, n_users, prior_alpha=1, prior_beta=1, verbose=True)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"THOMPSON SAMPLING RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for variant in ['A', 'B', 'C']:\n",
    "    n = results_ts['n_shown'][variant]\n",
    "    conv = results_ts['n_converted'][variant]\n",
    "    rate = conv / n if n > 0 else 0\n",
    "    traffic_pct = 100 * n / n_users\n",
    "    \n",
    "    print(f\"\\nVariant {variant}:\")\n",
    "    print(f\"  Traffic allocation: {traffic_pct:.1f}% ({n:,} users)\")\n",
    "    print(f\"  Conversions: {conv:,} ({rate*100:.2f}%)\")\n",
    "    print(f\"  Posterior: Beta({results_ts['alpha'][variant]:.0f}, {results_ts['beta'][variant]:.0f})\")\n",
    "\n",
    "print(f\"\\nTotal conversions: {results_ts['total_conversions']:,} / {n_users:,}\")\n",
    "print(f\"Overall conversion rate: {results_ts['total_conversions'] / n_users * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare with fixed allocation\n",
    "def fixed_allocation(true_rates, n_users):\n",
    "    \"\"\"Simulate fixed equal traffic allocation.\"\"\"\n",
    "    variants = list(true_rates.keys())\n",
    "    n_variants = len(variants)\n",
    "    \n",
    "    n_shown = {v: 0 for v in variants}\n",
    "    n_converted = {v: 0 for v in variants}\n",
    "    total_conversions = 0\n",
    "    \n",
    "    for user_id in range(n_users):\n",
    "        # Equal allocation\n",
    "        chosen = variants[user_id % n_variants]\n",
    "        \n",
    "        # Simulate outcome\n",
    "        converted = np.random.random() < true_rates[chosen]\n",
    "        \n",
    "        n_shown[chosen] += 1\n",
    "        n_converted[chosen] += converted\n",
    "        total_conversions += converted\n",
    "    \n",
    "    return {\n",
    "        'n_shown': n_shown,\n",
    "        'n_converted': n_converted,\n",
    "        'total_conversions': total_conversions\n",
    "    }\n",
    "\n",
    "print(f\"\\nSimulating fixed allocation with {n_users:,} users...\\n\")\n",
    "results_fixed = fixed_allocation(true_rates, n_users)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"FIXED ALLOCATION RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for variant in ['A', 'B', 'C']:\n",
    "    n = results_fixed['n_shown'][variant]\n",
    "    conv = results_fixed['n_converted'][variant]\n",
    "    rate = conv / n if n > 0 else 0\n",
    "    traffic_pct = 100 * n / n_users\n",
    "    \n",
    "    print(f\"\\nVariant {variant}:\")\n",
    "    print(f\"  Traffic allocation: {traffic_pct:.1f}% ({n:,} users)\")\n",
    "    print(f\"  Conversions: {conv:,} ({rate*100:.2f}%)\")\n",
    "\n",
    "print(f\"\\nTotal conversions: {results_fixed['total_conversions']:,} / {n_users:,}\")\n",
    "print(f\"Overall conversion rate: {results_fixed['total_conversions'] / n_users * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare performance\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPARISON: THOMPSON SAMPLING vs FIXED ALLOCATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Compute optimal (always show best variant)\n",
    "optimal_conversions = n_users * best_rate\n",
    "\n",
    "# Compute regret\n",
    "regret_ts = optimal_conversions - results_ts['total_conversions']\n",
    "regret_fixed = optimal_conversions - results_fixed['total_conversions']\n",
    "\n",
    "print(f\"\\nOptimal (always show {best_variant}):\")\n",
    "print(f\"  Total conversions: {optimal_conversions:.0f}\")\n",
    "\n",
    "print(f\"\\nThompson Sampling:\")\n",
    "print(f\"  Total conversions: {results_ts['total_conversions']:,}\")\n",
    "print(f\"  Regret: {regret_ts:.0f} conversions\")\n",
    "print(f\"  Efficiency: {results_ts['total_conversions'] / optimal_conversions * 100:.2f}%\")\n",
    "\n",
    "print(f\"\\nFixed Allocation:\")\n",
    "print(f\"  Total conversions: {results_fixed['total_conversions']:,}\")\n",
    "print(f\"  Regret: {regret_fixed:.0f} conversions\")\n",
    "print(f\"  Efficiency: {results_fixed['total_conversions'] / optimal_conversions * 100:.2f}%\")\n",
    "\n",
    "print(f\"\\nüìä Thompson Sampling Advantage:\")\n",
    "extra_conversions = results_ts['total_conversions'] - results_fixed['total_conversions']\n",
    "print(f\"  Extra conversions: {extra_conversions:.0f}\")\n",
    "print(f\"  Improvement: {extra_conversions / results_fixed['total_conversions'] * 100:.2f}%\")\n",
    "print(f\"  Regret reduction: {(regret_fixed - regret_ts) / regret_fixed * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize: Probability of being best over time\n",
    "history = results_ts['history']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "ax.plot(history['user'], history['prob_A_best'], label='P(A is best)', linewidth=2, color='#2ecc71')\n",
    "ax.plot(history['user'], history['prob_B_best'], label='P(B is best)', linewidth=2, color='#e74c3c')\n",
    "ax.plot(history['user'], history['prob_C_best'], label='P(C is best)', linewidth=2, color='#3498db')\n",
    "\n",
    "ax.axhline(y=0.95, color='gray', linestyle='--', linewidth=1, alpha=0.5, label='95% threshold')\n",
    "\n",
    "ax.set_xlabel('Number of Users', fontsize=12)\n",
    "ax.set_ylabel('Probability of Being Best', fontsize=12)\n",
    "ax.set_title('Thompson Sampling: Learning Which Variant is Best', fontsize=14, fontweight='bold')\n",
    "ax.legend(loc='right', fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_ylim(0, 1.05)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Find when we reach 95% confidence\n",
    "confidence_idx = None\n",
    "for i, prob_a in enumerate(history['prob_A_best']):\n",
    "    if prob_a >= 0.95:\n",
    "        confidence_idx = i\n",
    "        break\n",
    "\n",
    "if confidence_idx is not None:\n",
    "    users_to_95 = history['user'][confidence_idx]\n",
    "    print(f\"\\n‚úì Reached 95% confidence that A is best after ~{users_to_95:,} users\")\n",
    "else:\n",
    "    print(f\"\\n‚ö† Did not reach 95% confidence within {n_users:,} users\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Key Insights from Simulation\n",
    "\n",
    "### 1. Dynamic Traffic Allocation\n",
    "\n",
    "Thompson sampling **automatically** allocated:\n",
    "- **~60-70% traffic to variant A** (the best performer)\n",
    "- **~15-20% traffic to variant C** (middle performer)\n",
    "- **~10-15% traffic to variant B** (worst performer)\n",
    "\n",
    "Compare this to fixed allocation (33.3% each) ‚Äî Thompson sampling **minimized waste**.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Faster Convergence\n",
    "\n",
    "Thompson sampling reached **95% confidence** much faster than fixed allocation would allow for an NHST test.\n",
    "\n",
    "Why?\n",
    "- **More samples from better variants** ‚Üí faster learning about what's actually good\n",
    "- **Fewer samples from bad variants** ‚Üí less time wasted on unproductive exploration\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Higher Total Conversions\n",
    "\n",
    "By routing more traffic to better variants, Thompson sampling achieved **more total conversions** than fixed allocation.\n",
    "\n",
    "This is the essence of **regret minimization**:\n",
    "- Traditional A/B testing: \"Learn which is best\"\n",
    "- Thompson sampling: \"Maximize total conversions while learning\"\n",
    "\n",
    "---\n",
    "\n",
    "### 4. No Stopping Rule Needed\n",
    "\n",
    "Unlike NHST:\n",
    "- **No need to pre-compute sample size**\n",
    "- **No need to wait for significance**\n",
    "- **Can check results anytime** without \"p-hacking\"\n",
    "- **Algorithm keeps improving** the longer it runs\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding New Variants Dynamically\n",
    "\n",
    "One of Thompson sampling's greatest advantages: **new variants can enter at any time**.\n",
    "\n",
    "### How It Works\n",
    "\n",
    "1. **New variant arrives**: Initialize with prior Beta(1, 1) (or weakly informative prior)\n",
    "2. **Immediately participates**: Competes in sampling with existing variants\n",
    "3. **Gets explored**: Wide posterior ‚Üí sometimes samples high ‚Üí gets traffic\n",
    "4. **Proves itself or fades**: Good variants get more traffic; bad ones get less\n",
    "\n",
    "No need to:\n",
    "- Stop the test\n",
    "- Redistribute traffic manually\n",
    "- Recalculate sample sizes\n",
    "- Worry about multiple comparisons\n",
    "\n",
    "### Example: Adding Variant D Mid-Test\n",
    "\n",
    "Suppose after 2000 users, product team creates **variant D** with 72% conversion (better than all existing variants).\n",
    "\n",
    "What happens:\n",
    "1. **D starts with Beta(1, 1)** ‚Äî knows nothing\n",
    "2. **D gets explored** ‚Äî wide posterior sometimes samples high\n",
    "3. **D converts well** ‚Äî posterior narrows around 72%\n",
    "4. **D wins most samples** ‚Äî traffic shifts to D\n",
    "5. **A/B/C fade out** ‚Äî naturally get less traffic\n",
    "\n",
    "Let's simulate this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def thompson_sampling_with_new_variant(true_rates, n_users_before, new_variant_rate, n_users_after):\n",
    "    \"\"\"\n",
    "    Simulate Thompson sampling where a new variant is added mid-experiment.\n",
    "    \"\"\"\n",
    "    variants = list(true_rates.keys())\n",
    "    \n",
    "    # Initialize posteriors\n",
    "    alpha = {v: 1 for v in variants}\n",
    "    beta = {v: 1 for v in variants}\n",
    "    \n",
    "    n_shown = {v: 0 for v in variants}\n",
    "    n_converted = {v: 0 for v in variants}\n",
    "    \n",
    "    history = {'user': [], 'traffic_A': [], 'traffic_B': [], 'traffic_C': [], 'traffic_D': []}\n",
    "    \n",
    "    # Phase 1: Before new variant\n",
    "    print(f\"Phase 1: Running with variants {variants}...\")\n",
    "    for user_id in range(n_users_before):\n",
    "        samples = {v: np.random.beta(alpha[v], beta[v]) for v in variants}\n",
    "        chosen = max(samples, key=samples.get)\n",
    "        converted = np.random.random() < true_rates[chosen]\n",
    "        \n",
    "        alpha[chosen] += converted\n",
    "        beta[chosen] += (1 - converted)\n",
    "        n_shown[chosen] += 1\n",
    "        n_converted[chosen] += converted\n",
    "    \n",
    "    print(f\"After {n_users_before} users:\")\n",
    "    for v in variants:\n",
    "        pct = 100 * n_shown[v] / n_users_before\n",
    "        print(f\"  {v}: {pct:.1f}% traffic, Beta({alpha[v]:.0f}, {beta[v]:.0f})\")\n",
    "    \n",
    "    # Phase 2: Add new variant D\n",
    "    print(f\"\\nüÜï Adding new variant D with true rate {new_variant_rate*100:.1f}%...\\n\")\n",
    "    true_rates['D'] = new_variant_rate\n",
    "    variants.append('D')\n",
    "    alpha['D'] = 1  # Start with uninformative prior\n",
    "    beta['D'] = 1\n",
    "    n_shown['D'] = 0\n",
    "    n_converted['D'] = 0\n",
    "    \n",
    "    # Continue experiment\n",
    "    total_users = n_users_before\n",
    "    for user_id in range(n_users_after):\n",
    "        samples = {v: np.random.beta(alpha[v], beta[v]) for v in variants}\n",
    "        chosen = max(samples, key=samples.get)\n",
    "        converted = np.random.random() < true_rates[chosen]\n",
    "        \n",
    "        alpha[chosen] += converted\n",
    "        beta[chosen] += (1 - converted)\n",
    "        n_shown[chosen] += 1\n",
    "        n_converted[chosen] += converted\n",
    "        total_users += 1\n",
    "        \n",
    "        # Track traffic allocation every 50 users\n",
    "        if user_id % 50 == 0:\n",
    "            history['user'].append(total_users)\n",
    "            for v in ['A', 'B', 'C', 'D']:\n",
    "                if v in n_shown:\n",
    "                    history[f'traffic_{v}'].append(100 * n_shown[v] / total_users)\n",
    "                else:\n",
    "                    history[f'traffic_{v}'].append(0)\n",
    "    \n",
    "    print(f\"\\nAfter {total_users} total users:\")\n",
    "    for v in variants:\n",
    "        pct = 100 * n_shown[v] / total_users\n",
    "        print(f\"  {v}: {pct:.1f}% traffic, Beta({alpha[v]:.0f}, {beta[v]:.0f})\")\n",
    "    \n",
    "    return history, n_shown, total_users\n",
    "\n",
    "# Run simulation\n",
    "true_rates_initial = {'A': 0.7016, 'B': 0.6824, 'C': 0.6903}\n",
    "history, n_shown, total = thompson_sampling_with_new_variant(\n",
    "    true_rates_initial.copy(), \n",
    "    n_users_before=2000, \n",
    "    new_variant_rate=0.72,  # D is better than A!\n",
    "    n_users_after=3000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize traffic allocation over time\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "ax.plot(history['user'], history['traffic_A'], label='Variant A', linewidth=2, color='#2ecc71')\n",
    "ax.plot(history['user'], history['traffic_B'], label='Variant B', linewidth=2, color='#e74c3c')\n",
    "ax.plot(history['user'], history['traffic_C'], label='Variant C', linewidth=2, color='#3498db')\n",
    "ax.plot(history['user'], history['traffic_D'], label='Variant D (new)', linewidth=2, color='#f39c12', linestyle='--')\n",
    "\n",
    "ax.axvline(x=2000, color='gray', linestyle=':', linewidth=2, alpha=0.7, label='D added')\n",
    "\n",
    "ax.set_xlabel('Number of Users', fontsize=12)\n",
    "ax.set_ylabel('Traffic Allocation (%)', fontsize=12)\n",
    "ax.set_title('Thompson Sampling: Dynamic Traffic Allocation with New Variant', fontsize=14, fontweight='bold')\n",
    "ax.legend(loc='right', fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_ylim(0, 80)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä Key Observations:\")\n",
    "print(\"  1. Before user 2000: A gets most traffic (it's the best)\")\n",
    "print(\"  2. At user 2000: D enters with uninformative prior\")\n",
    "print(\"  3. D gets explored: Wide posterior ‚Üí sometimes samples high\")\n",
    "print(\"  4. D proves superior: Converts at 72% ‚Üí posterior narrows\")\n",
    "print(\"  5. Traffic shifts to D: Algorithm automatically reallocates\")\n",
    "print(\"  6. A/B/C fade out: Naturally get less traffic as D dominates\")\n",
    "print(\"\\n‚úì NO manual intervention needed ‚Äî algorithm adapts automatically!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Practical Implementation Considerations\n",
    "\n",
    "### 1. Choosing Priors\n",
    "\n",
    "**Non-informative**: Beta(1, 1)\n",
    "- Use when you truly know nothing\n",
    "- Allows maximum influence from data\n",
    "- Good for fair comparison of new variants\n",
    "\n",
    "**Weakly informative**: Beta($\\alpha_0$, $\\beta_0$) centered on control rate\n",
    "- Use when variants should be \"around\" control performance\n",
    "- Faster convergence\n",
    "- Still allows data to dominate\n",
    "\n",
    "**Rule of thumb**: $\\alpha_0 + \\beta_0 \\approx 10-20$ for weak prior strength\n",
    "\n",
    "---\n",
    "\n",
    "### 2. When to Stop\n",
    "\n",
    "Unlike NHST, Thompson sampling has **no fixed stopping rule**.\n",
    "\n",
    "Options:\n",
    "\n",
    "**Business threshold**: Stop when P(best variant is best) > 95%\n",
    "```python\n",
    "if prob_best > 0.95:\n",
    "    deploy_winner()\n",
    "```\n",
    "\n",
    "**Traffic concentration**: Stop when winner gets >80% of traffic\n",
    "```python\n",
    "if traffic_to_best / total_traffic > 0.80:\n",
    "    deploy_winner()\n",
    "```\n",
    "\n",
    "**Time limit**: Run for N days regardless (still gets benefits of dynamic allocation)\n",
    "\n",
    "**Never stop**: Keep running indefinitely as a self-optimizing system\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Implementation in Traffic Splitters\n",
    "\n",
    "**Centralized approach**:\n",
    "```python\n",
    "class ThompsonSamplingTrafficSplitter:\n",
    "    def __init__(self, variants):\n",
    "        self.variants = variants\n",
    "        self.alpha = {v: 1 for v in variants}\n",
    "        self.beta = {v: 1 for v in variants}\n",
    "    \n",
    "    def choose_variant(self):\n",
    "        \"\"\"Called for each user.\"\"\"\n",
    "        samples = {v: np.random.beta(self.alpha[v], self.beta[v]) \n",
    "                   for v in self.variants}\n",
    "        return max(samples, key=samples.get)\n",
    "    \n",
    "    def update(self, variant, converted):\n",
    "        \"\"\"Called after user outcome is observed.\"\"\"\n",
    "        self.alpha[variant] += converted\n",
    "        self.beta[variant] += (1 - converted)\n",
    "    \n",
    "    def add_variant(self, new_variant):\n",
    "        \"\"\"Add new variant dynamically.\"\"\"\n",
    "        self.variants.append(new_variant)\n",
    "        self.alpha[new_variant] = 1\n",
    "        self.beta[new_variant] = 1\n",
    "```\n",
    "\n",
    "**Distributed approach** (for high-scale systems):\n",
    "- Store (Œ±, Œ≤) parameters in distributed cache (Redis, etc.)\n",
    "- Each server samples locally\n",
    "- Batch updates to reduce contention\n",
    "- Acceptable to be slightly out-of-sync (algorithm is robust)\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Monitoring\n",
    "\n",
    "Track:\n",
    "- **Current traffic allocation** per variant\n",
    "- **Posterior means** (estimated conversion rates)\n",
    "- **Credible intervals** (uncertainty)\n",
    "- **P(variant is best)** for each variant\n",
    "- **Total conversions** and **regret**\n",
    "\n",
    "Alert if:\n",
    "- Traffic becomes too concentrated (>95% to one variant) before you're ready\n",
    "- Posteriors stop updating (suggests implementation bug)\n",
    "- Observed rates deviate significantly from posteriors (data quality issue)\n",
    "\n",
    "---\n",
    "\n",
    "### 5. A/A Testing\n",
    "\n",
    "Before deploying Thompson sampling in production:\n",
    "\n",
    "**Run A/A test**: Split traffic between two identical experiences\n",
    "- Should allocate ~50/50 in the long run\n",
    "- Should not confidently declare a winner\n",
    "- Validates implementation correctness\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary: From Bayesian Posteriors to Optimal Traffic Allocation\n",
    "\n",
    "### The Journey\n",
    "\n",
    "1. **Bayesian inference** gives us posterior distributions for conversion rates\n",
    "2. **Sampling from posteriors** naturally encodes exploration vs. exploitation\n",
    "3. **Thompson sampling** turns this into a simple, optimal traffic allocation algorithm\n",
    "4. **Dynamic reallocation** minimizes regret and maximizes total conversions\n",
    "5. **Continuous adaptation** allows adding/removing variants without restart\n",
    "\n",
    "---\n",
    "\n",
    "### Why Thompson Sampling is Superior\n",
    "\n",
    "| Aspect | Traditional A/B | Thompson Sampling |\n",
    "|--------|----------------|-------------------|\n",
    "| **Traffic allocation** | Fixed (e.g., 33/33/33) | Dynamic (adapts to performance) |\n",
    "| **Total conversions** | Suboptimal (wastes traffic) | Near-optimal (minimizes regret) |\n",
    "| **Time to decision** | Wait for significance | Continuous improvement |\n",
    "| **Adding variants** | Restart test | Add anytime |\n",
    "| **Removing variants** | Manual rebalance | Automatic fade-out |\n",
    "| **Multiple comparisons** | Need corrections | No problem |\n",
    "| **Stopping rule** | Pre-determined | Flexible |\n",
    "| **Implementation** | Complex statistics | 5 lines of code |\n",
    "\n",
    "---\n",
    "\n",
    "### When to Use Thompson Sampling\n",
    "\n",
    "‚úÖ **Perfect for**:\n",
    "- Product experimentation with multiple variants\n",
    "- Continuous optimization (content, recommendations, ads)\n",
    "- High-traffic scenarios (thousands of users per day)\n",
    "- Dynamic environments (variants added/removed frequently)\n",
    "- When you care about **total conversions**, not just identifying the winner\n",
    "\n",
    "‚ö†Ô∏è **Consider alternatives when**:\n",
    "- Very low traffic (<100 users per day) ‚Äî may be too slow\n",
    "- Regulatory requirements for fixed sample sizes (pharma, medical devices)\n",
    "- Need explainable p-values for stakeholders (though Bayesian probabilities are more interpretable)\n",
    "\n",
    "---\n",
    "\n",
    "### Implementation Checklist\n",
    "\n",
    "‚úì Choose appropriate priors (weakly informative recommended)  \n",
    "‚úì Implement core algorithm (choose, observe, update)  \n",
    "‚úì Add monitoring (traffic allocation, posteriors, probabilities)  \n",
    "‚úì Run A/A test to validate implementation  \n",
    "‚úì Define stopping criteria (business threshold, time limit, or continuous)  \n",
    "‚úì Plan for adding/removing variants  \n",
    "‚úì Document for stakeholders  \n",
    "\n",
    "---\n",
    "\n",
    "### The Bottom Line\n",
    "\n",
    "**Thompson sampling transforms Bayesian posteriors into a self-optimizing traffic splitter.**\n",
    "\n",
    "No complex statistics. No sample size calculations. No stopping rules. No multiple comparison corrections.\n",
    "\n",
    "Just:\n",
    "1. Sample\n",
    "2. Choose\n",
    "3. Observe\n",
    "4. Update\n",
    "5. Repeat\n",
    "\n",
    "**Mathematics meets elegance. Theory meets practice. Bayesian meets optimal.**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Reading\n",
    "\n",
    "### Academic Papers\n",
    "\n",
    "- **Thompson, W. R. (1933)**. \"On the likelihood that one unknown probability exceeds another in view of the evidence of two samples.\" *Biometrika*, 25(3/4), 285-294.\n",
    "  - The original Thompson sampling paper\n",
    "\n",
    "- **Chapelle, O., & Li, L. (2011)**. \"An empirical evaluation of thompson sampling.\" *Advances in neural information processing systems*, 24.\n",
    "  - Empirical evidence for Thompson sampling's effectiveness\n",
    "\n",
    "- **Agrawal, S., & Goyal, N. (2012)**. \"Analysis of thompson sampling for the multi-armed bandit problem.\" *Conference on Learning Theory*.\n",
    "  - Theoretical analysis of regret bounds\n",
    "\n",
    "### Online Resources\n",
    "\n",
    "- **Chris Stucchio's blog**: Extensive practical guides on Bayesian A/B testing\n",
    "- **Evan Miller's website**: Interactive calculators and explanations\n",
    "- **VWO, Optimizely documentation**: Real-world implementations\n",
    "\n",
    "### Books\n",
    "\n",
    "- **Gelman et al.** \"Bayesian Data Analysis\" ‚Äî comprehensive Bayesian statistics\n",
    "- **Lattimore & Szepesv√°ri** \"Bandit Algorithms\" ‚Äî theoretical treatment of bandits\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
