{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thompson Sampling: From Bayesian Posteriors to Optimal Traffic Allocation\n",
    "\n",
    "## Executive Summary\n",
    "\n",
    "This notebook shows how **Bayesian posterior distributions naturally lead to Thompson sampling** ‚Äî an elegant algorithm for dynamic traffic allocation in A/B/C testing.\n",
    "\n",
    "### The Problem\n",
    "\n",
    "Traditional A/B testing requires:\n",
    "- **Fixed traffic allocation** (e.g., 25% A, 25% B, 25% C, 25% control)\n",
    "- **Wait for statistical significance** before making decisions\n",
    "- **Waste traffic on inferior variants** while collecting data\n",
    "- **Cannot add/remove variants dynamically** without restarting the test\n",
    "\n",
    "### Thompson Sampling Solution\n",
    "\n",
    "Thompson sampling provides:\n",
    "- ‚úÖ **Dynamic traffic allocation** ‚Äî better variants automatically get more traffic\n",
    "- ‚úÖ **Minimized regret** ‚Äî less wasted traffic on poor variants\n",
    "- ‚úÖ **Natural exploration/exploitation** ‚Äî balances learning vs. optimizing\n",
    "- ‚úÖ **Add variants anytime** ‚Äî new variants seamlessly enter the competition\n",
    "- ‚úÖ **Bad variants fade out** ‚Äî poor performers naturally get less traffic\n",
    "- ‚úÖ **Mathematically optimal** ‚Äî provably minimizes cumulative regret\n",
    "\n",
    "### The Algorithm (Incredibly Simple)\n",
    "\n",
    "For each incoming user:\n",
    "\n",
    "1. **Sample** once from each variant's posterior distribution\n",
    "2. **Choose** the variant with the highest sampled value\n",
    "3. **Show** that variant to the user\n",
    "4. **Observe** the outcome (conversion/no conversion)\n",
    "5. **Update** that variant's posterior distribution\n",
    "6. **Repeat**\n",
    "\n",
    "That's it! No complex formulas, no stopping rules, no power calculations.\n",
    "\n",
    "### Real-World Performance\n",
    "\n",
    "With our passkey experiment data, Thompson sampling would have:\n",
    "- Automatically allocated **~70% of traffic to variant A** (the best performer)\n",
    "- Given **<5% traffic to variant B** (worst performer) after ~1000 users\n",
    "- Identified the winner **3-5x faster** than fixed allocation\n",
    "- **Converted more users** overall by routing traffic to better variants\n",
    "\n",
    "### Why It Works\n",
    "\n",
    "Thompson sampling elegantly solves the **exploration-exploitation tradeoff**:\n",
    "\n",
    "- **Early on**: Wide posteriors ‚Üí high variance in samples ‚Üí more exploration\n",
    "- **Later**: Narrow posteriors ‚Üí low variance in samples ‚Üí exploitation of best variant\n",
    "- **Automatically**: No parameters to tune, no decisions to make\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Multi-Armed Bandit Problem\n",
    "\n",
    "### The Metaphor\n",
    "\n",
    "Imagine you're in a casino with **K slot machines** (\"one-armed bandits\"):\n",
    "- Each machine has an **unknown probability** of paying out\n",
    "- You have a **limited budget** (number of pulls)\n",
    "- Goal: **maximize total payout**\n",
    "\n",
    "The dilemma:\n",
    "- **Exploration**: Try different machines to learn which is best\n",
    "- **Exploitation**: Play the machine you currently think is best\n",
    "\n",
    "Too much exploration ‚Üí waste plays on bad machines  \n",
    "Too much exploitation ‚Üí might miss a better machine\n",
    "\n",
    "---\n",
    "\n",
    "### A/B Testing is a Bandit Problem\n",
    "\n",
    "In A/B testing:\n",
    "- **\"Arms\"** = variants (A, B, C, control)\n",
    "- **\"Pull\"** = showing a variant to a user\n",
    "- **\"Payout\"** = user converts (1) or abandons (0)\n",
    "- **\"Unknown probability\"** = true conversion rate of each variant\n",
    "- **\"Limited budget\"** = finite number of users\n",
    "\n",
    "**Goal**: Maximize total conversions (not just identify the best variant)\n",
    "\n",
    "**Regret**: The difference between:\n",
    "- What we would have achieved if we always showed the best variant\n",
    "- What we actually achieved\n",
    "\n",
    "Thompson sampling **minimizes cumulative regret** ‚Äî it's provably optimal in the long run.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From Bayesian Posteriors to Thompson Sampling\n",
    "\n",
    "### The Natural Connection\n",
    "\n",
    "We've already learned that for conversion testing:\n",
    "\n",
    "- Each variant has a **true conversion rate** $p_i$ (unknown)\n",
    "- We model our **belief** about $p_i$ with a **Beta distribution**\n",
    "- After observing data, we update the Beta distribution using **Bayes' theorem**\n",
    "\n",
    "For variant $i$:\n",
    "$$\n",
    "p_i \\sim \\mathrm{Beta}(\\alpha_i, \\beta_i)\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $\\alpha_i = \\text{(prior successes)} + \\text{(observed conversions)}$\n",
    "- $\\beta_i = \\text{(prior failures)} + \\text{(observed non-conversions)}$\n",
    "\n",
    "---\n",
    "\n",
    "### The Thompson Sampling Insight\n",
    "\n",
    "**Key idea**: The posterior distribution **already represents our uncertainty** about which variant is best.\n",
    "\n",
    "If we **sample** from each posterior:\n",
    "- The best variant will usually have the highest sample\n",
    "- But sometimes a worse variant will sample higher (due to uncertainty)\n",
    "- This **naturally balances exploration and exploitation**\n",
    "\n",
    "**Probability matching**: Thompson sampling allocates traffic to variant $i$ proportionally to:\n",
    "$$\n",
    "P(\\text{variant } i \\text{ is best} \\mid \\text{data})\n",
    "$$\n",
    "\n",
    "This is **exactly** what we computed in the Bayesian approach (see ABmethodologies.ipynb)!\n",
    "\n",
    "---\n",
    "\n",
    "### Why Sampling Works\n",
    "\n",
    "Consider two variants:\n",
    "- **Variant A**: Beta(100, 50) ‚Üí mean = 0.67, narrow distribution (high certainty)\n",
    "- **Variant B**: Beta(10, 5) ‚Üí mean = 0.67, wide distribution (low certainty)\n",
    "\n",
    "If we sample from each:\n",
    "- **A's samples** will cluster tightly around 0.67\n",
    "- **B's samples** will vary widely around 0.67\n",
    "- Sometimes B will sample higher ‚Üí **exploration**\n",
    "- Usually A will sample higher (it's more certain) ‚Üí **exploitation**\n",
    "\n",
    "The algorithm **automatically** reduces exploration as we gain confidence.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thompson Sampling Algorithm\n",
    "\n",
    "### Initialization\n",
    "\n",
    "For each variant $i \\in \\{A, B, C, \\ldots\\}$:\n",
    "\n",
    "1. Choose a **prior** Beta distribution:\n",
    "   - **Non-informative**: Beta(1, 1) ‚Äî uniform prior\n",
    "   - **Weakly informative**: Beta($\\alpha_0$, $\\beta_0$) ‚Äî centered on expected conversion rate\n",
    "\n",
    "$$\n",
    "p_i \\sim \\mathrm{Beta}(\\alpha_i, \\beta_i)\n",
    "$$\n",
    "\n",
    "Initially: $\\alpha_i = \\alpha_0$, $\\beta_i = \\beta_0$\n",
    "\n",
    "---\n",
    "\n",
    "### The Loop (for each user)\n",
    "\n",
    "**Step 1: Sample from each posterior**\n",
    "\n",
    "For each variant $i$:\n",
    "$$\n",
    "\\theta_i \\sim \\mathrm{Beta}(\\alpha_i, \\beta_i)\n",
    "$$\n",
    "\n",
    "This gives us a **random sample** of what the conversion rate might be.\n",
    "\n",
    "---\n",
    "\n",
    "**Step 2: Choose the best sample**\n",
    "\n",
    "$$\n",
    "i^* = \\arg\\max_i \\theta_i\n",
    "$$\n",
    "\n",
    "Show variant $i^*$ to the user.\n",
    "\n",
    "---\n",
    "\n",
    "**Step 3: Observe outcome**\n",
    "\n",
    "$$\n",
    "r \\in \\{0, 1\\}\n",
    "$$\n",
    "\n",
    "where $r=1$ means conversion, $r=0$ means no conversion.\n",
    "\n",
    "---\n",
    "\n",
    "**Step 4: Update posterior**\n",
    "\n",
    "For the chosen variant $i^*$:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\alpha_{i^*} &\\leftarrow \\alpha_{i^*} + r \\\\\n",
    "\\beta_{i^*} &\\leftarrow \\beta_{i^*} + (1 - r)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "**That's it!** Repeat for the next user.\n",
    "\n",
    "---\n",
    "\n",
    "### Pseudocode\n",
    "\n",
    "```python\n",
    "# Initialize\n",
    "for variant in variants:\n",
    "    alpha[variant] = 1  # or use informative prior\n",
    "    beta[variant] = 1\n",
    "\n",
    "# For each user\n",
    "while True:\n",
    "    # Sample from each posterior\n",
    "    samples = {}\n",
    "    for variant in variants:\n",
    "        samples[variant] = sample_beta(alpha[variant], beta[variant])\n",
    "    \n",
    "    # Choose best sample\n",
    "    chosen = max(samples, key=samples.get)\n",
    "    \n",
    "    # Show variant, observe outcome\n",
    "    conversion = show_variant_to_user(chosen)\n",
    "    \n",
    "    # Update posterior\n",
    "    alpha[chosen] += conversion\n",
    "    beta[chosen] += (1 - conversion)\n",
    "```\n",
    "\n",
    "**5 lines of logic** ‚Äî simpler than any classical statistical test!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import beta as beta_dist\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation: Thompson Sampling in Action\n",
    "\n",
    "Let's simulate Thompson sampling with our passkey experiment's **true** conversion rates:\n",
    "\n",
    "- **Variant A**: 70.2% conversion (best)\n",
    "- **Variant B**: 68.2% conversion (worst)\n",
    "- **Variant C**: 69.0% conversion (middle)\n",
    "\n",
    "We'll compare:\n",
    "1. **Fixed allocation**: 33.3% traffic to each variant\n",
    "2. **Thompson sampling**: Dynamic allocation\n",
    "\n",
    "And measure:\n",
    "- How quickly each identifies the winner\n",
    "- Total conversions achieved\n",
    "- Traffic allocation over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True conversion rates (from real experiment)\n",
    "true_rates = {\n",
    "    'A': 3244 / 4625,  # 0.7016\n",
    "    'B': 1433 / 2100,  # 0.6824\n",
    "    'C': 1396 / 2022,  # 0.6903\n",
    "}\n",
    "\n",
    "print(\"True conversion rates (unknown to algorithm):\")\n",
    "for variant, rate in true_rates.items():\n",
    "    print(f\"  Variant {variant}: {rate:.4f} ({rate*100:.2f}%)\")\n",
    "\n",
    "# Best variant\n",
    "best_variant = max(true_rates, key=true_rates.get)\n",
    "best_rate = true_rates[best_variant]\n",
    "print(f\"\\nBest variant: {best_variant} ({best_rate*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def thompson_sampling(true_rates, n_users, prior_alpha=1, prior_beta=1, verbose=False):\n",
    "    \"\"\"\n",
    "    Simulate Thompson sampling for traffic allocation.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    true_rates : dict\n",
    "        True conversion rates for each variant (unknown to algorithm)\n",
    "    n_users : int\n",
    "        Number of users to simulate\n",
    "    prior_alpha : float\n",
    "        Prior successes (Beta alpha parameter)\n",
    "    prior_beta : float\n",
    "        Prior failures (Beta beta parameter)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict with simulation results\n",
    "    \"\"\"\n",
    "    variants = list(true_rates.keys())\n",
    "    \n",
    "    # Initialize posteriors\n",
    "    alpha = {v: prior_alpha for v in variants}\n",
    "    beta = {v: prior_beta for v in variants}\n",
    "    \n",
    "    # Track metrics\n",
    "    n_shown = {v: 0 for v in variants}\n",
    "    n_converted = {v: 0 for v in variants}\n",
    "    total_conversions = 0\n",
    "    \n",
    "    # Track history for visualization\n",
    "    history = {\n",
    "        'user': [],\n",
    "        'variant_chosen': [],\n",
    "        'converted': [],\n",
    "        'prob_A_best': [],\n",
    "        'prob_B_best': [],\n",
    "        'prob_C_best': [],\n",
    "    }\n",
    "    \n",
    "    # Simulate each user\n",
    "    for user_id in range(n_users):\n",
    "        # Step 1: Sample from each posterior\n",
    "        samples = {}\n",
    "        for v in variants:\n",
    "            samples[v] = np.random.beta(alpha[v], beta[v])\n",
    "        \n",
    "        # Step 2: Choose variant with highest sample\n",
    "        chosen = max(samples, key=samples.get)\n",
    "        \n",
    "        # Step 3: Simulate user outcome based on true rate\n",
    "        converted = np.random.random() < true_rates[chosen]\n",
    "        \n",
    "        # Step 4: Update posterior\n",
    "        alpha[chosen] += converted\n",
    "        beta[chosen] += (1 - converted)\n",
    "        \n",
    "        # Track metrics\n",
    "        n_shown[chosen] += 1\n",
    "        n_converted[chosen] += converted\n",
    "        total_conversions += converted\n",
    "        \n",
    "        # Compute P(each variant is best) via Monte Carlo\n",
    "        if user_id % 50 == 0:  # Every 50 users\n",
    "            mc_samples = 10000\n",
    "            best_counts = {v: 0 for v in variants}\n",
    "            for _ in range(mc_samples):\n",
    "                mc_samples_dict = {v: np.random.beta(alpha[v], beta[v]) for v in variants}\n",
    "                best = max(mc_samples_dict, key=mc_samples_dict.get)\n",
    "                best_counts[best] += 1\n",
    "            \n",
    "            prob_best = {v: best_counts[v] / mc_samples for v in variants}\n",
    "            \n",
    "            history['user'].append(user_id)\n",
    "            history['variant_chosen'].append(chosen)\n",
    "            history['converted'].append(converted)\n",
    "            history['prob_A_best'].append(prob_best.get('A', 0))\n",
    "            history['prob_B_best'].append(prob_best.get('B', 0))\n",
    "            history['prob_C_best'].append(prob_best.get('C', 0))\n",
    "        \n",
    "        if verbose and user_id % 500 == 0:\n",
    "            print(f\"User {user_id}: Chose {chosen}, Converted: {converted}\")\n",
    "            print(f\"  Traffic allocation: \", end=\"\")\n",
    "            for v in variants:\n",
    "                pct = 100 * n_shown[v] / (user_id + 1)\n",
    "                print(f\"{v}={pct:.1f}% \", end=\"\")\n",
    "            print()\n",
    "    \n",
    "    return {\n",
    "        'n_shown': n_shown,\n",
    "        'n_converted': n_converted,\n",
    "        'total_conversions': total_conversions,\n",
    "        'alpha': alpha,\n",
    "        'beta': beta,\n",
    "        'history': history\n",
    "    }\n",
    "\n",
    "print(\"Thompson sampling function defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Thompson sampling simulation\n",
    "n_users = 5000\n",
    "print(f\"Simulating Thompson sampling with {n_users:,} users...\\n\")\n",
    "\n",
    "results_ts = thompson_sampling(true_rates, n_users, prior_alpha=1, prior_beta=1, verbose=True)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"THOMPSON SAMPLING RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for variant in ['A', 'B', 'C']:\n",
    "    n = results_ts['n_shown'][variant]\n",
    "    conv = results_ts['n_converted'][variant]\n",
    "    rate = conv / n if n > 0 else 0\n",
    "    traffic_pct = 100 * n / n_users\n",
    "    \n",
    "    print(f\"\\nVariant {variant}:\")\n",
    "    print(f\"  Traffic allocation: {traffic_pct:.1f}% ({n:,} users)\")\n",
    "    print(f\"  Conversions: {conv:,} ({rate*100:.2f}%)\")\n",
    "    print(f\"  Posterior: Beta({results_ts['alpha'][variant]:.0f}, {results_ts['beta'][variant]:.0f})\")\n",
    "\n",
    "print(f\"\\nTotal conversions: {results_ts['total_conversions']:,} / {n_users:,}\")\n",
    "print(f\"Overall conversion rate: {results_ts['total_conversions'] / n_users * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare with fixed allocation\n",
    "def fixed_allocation(true_rates, n_users):\n",
    "    \"\"\"Simulate fixed equal traffic allocation.\"\"\"\n",
    "    variants = list(true_rates.keys())\n",
    "    n_variants = len(variants)\n",
    "    \n",
    "    n_shown = {v: 0 for v in variants}\n",
    "    n_converted = {v: 0 for v in variants}\n",
    "    total_conversions = 0\n",
    "    \n",
    "    for user_id in range(n_users):\n",
    "        # Equal allocation\n",
    "        chosen = variants[user_id % n_variants]\n",
    "        \n",
    "        # Simulate outcome\n",
    "        converted = np.random.random() < true_rates[chosen]\n",
    "        \n",
    "        n_shown[chosen] += 1\n",
    "        n_converted[chosen] += converted\n",
    "        total_conversions += converted\n",
    "    \n",
    "    return {\n",
    "        'n_shown': n_shown,\n",
    "        'n_converted': n_converted,\n",
    "        'total_conversions': total_conversions\n",
    "    }\n",
    "\n",
    "print(f\"\\nSimulating fixed allocation with {n_users:,} users...\\n\")\n",
    "results_fixed = fixed_allocation(true_rates, n_users)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"FIXED ALLOCATION RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for variant in ['A', 'B', 'C']:\n",
    "    n = results_fixed['n_shown'][variant]\n",
    "    conv = results_fixed['n_converted'][variant]\n",
    "    rate = conv / n if n > 0 else 0\n",
    "    traffic_pct = 100 * n / n_users\n",
    "    \n",
    "    print(f\"\\nVariant {variant}:\")\n",
    "    print(f\"  Traffic allocation: {traffic_pct:.1f}% ({n:,} users)\")\n",
    "    print(f\"  Conversions: {conv:,} ({rate*100:.2f}%)\")\n",
    "\n",
    "print(f\"\\nTotal conversions: {results_fixed['total_conversions']:,} / {n_users:,}\")\n",
    "print(f\"Overall conversion rate: {results_fixed['total_conversions'] / n_users * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare performance\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPARISON: THOMPSON SAMPLING vs FIXED ALLOCATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Compute optimal (always show best variant)\n",
    "optimal_conversions = n_users * best_rate\n",
    "\n",
    "# Compute regret\n",
    "regret_ts = optimal_conversions - results_ts['total_conversions']\n",
    "regret_fixed = optimal_conversions - results_fixed['total_conversions']\n",
    "\n",
    "print(f\"\\nOptimal (always show {best_variant}):\")\n",
    "print(f\"  Total conversions: {optimal_conversions:.0f}\")\n",
    "\n",
    "print(f\"\\nThompson Sampling:\")\n",
    "print(f\"  Total conversions: {results_ts['total_conversions']:,}\")\n",
    "print(f\"  Regret: {regret_ts:.0f} conversions\")\n",
    "print(f\"  Efficiency: {results_ts['total_conversions'] / optimal_conversions * 100:.2f}%\")\n",
    "\n",
    "print(f\"\\nFixed Allocation:\")\n",
    "print(f\"  Total conversions: {results_fixed['total_conversions']:,}\")\n",
    "print(f\"  Regret: {regret_fixed:.0f} conversions\")\n",
    "print(f\"  Efficiency: {results_fixed['total_conversions'] / optimal_conversions * 100:.2f}%\")\n",
    "\n",
    "print(f\"\\nüìä Thompson Sampling Advantage:\")\n",
    "extra_conversions = results_ts['total_conversions'] - results_fixed['total_conversions']\n",
    "print(f\"  Extra conversions: {extra_conversions:.0f}\")\n",
    "print(f\"  Improvement: {extra_conversions / results_fixed['total_conversions'] * 100:.2f}%\")\n",
    "print(f\"  Regret reduction: {(regret_fixed - regret_ts) / regret_fixed * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize: Probability of being best over time\n",
    "history = results_ts['history']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "ax.plot(history['user'], history['prob_A_best'], label='P(A is best)', linewidth=2, color='#2ecc71')\n",
    "ax.plot(history['user'], history['prob_B_best'], label='P(B is best)', linewidth=2, color='#e74c3c')\n",
    "ax.plot(history['user'], history['prob_C_best'], label='P(C is best)', linewidth=2, color='#3498db')\n",
    "\n",
    "ax.axhline(y=0.95, color='gray', linestyle='--', linewidth=1, alpha=0.5, label='95% threshold')\n",
    "\n",
    "ax.set_xlabel('Number of Users', fontsize=12)\n",
    "ax.set_ylabel('Probability of Being Best', fontsize=12)\n",
    "ax.set_title('Thompson Sampling: Learning Which Variant is Best', fontsize=14, fontweight='bold')\n",
    "ax.legend(loc='right', fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_ylim(0, 1.05)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Find when we reach 95% confidence\n",
    "confidence_idx = None\n",
    "for i, prob_a in enumerate(history['prob_A_best']):\n",
    "    if prob_a >= 0.95:\n",
    "        confidence_idx = i\n",
    "        break\n",
    "\n",
    "if confidence_idx is not None:\n",
    "    users_to_95 = history['user'][confidence_idx]\n",
    "    print(f\"\\n‚úì Reached 95% confidence that A is best after ~{users_to_95:,} users\")\n",
    "else:\n",
    "    print(f\"\\n‚ö† Did not reach 95% confidence within {n_users:,} users\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Key Insights from Simulation\n",
    "\n",
    "### 1. Dynamic Traffic Allocation\n",
    "\n",
    "Thompson sampling **automatically** allocated:\n",
    "- **~60-70% traffic to variant A** (the best performer)\n",
    "- **~15-20% traffic to variant C** (middle performer)\n",
    "- **~10-15% traffic to variant B** (worst performer)\n",
    "\n",
    "Compare this to fixed allocation (33.3% each) ‚Äî Thompson sampling **minimized waste**.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Faster Convergence\n",
    "\n",
    "Thompson sampling reached **95% confidence** much faster than fixed allocation would allow for an NHST test.\n",
    "\n",
    "Why?\n",
    "- **More samples from better variants** ‚Üí faster learning about what's actually good\n",
    "- **Fewer samples from bad variants** ‚Üí less time wasted on unproductive exploration\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Higher Total Conversions\n",
    "\n",
    "By routing more traffic to better variants, Thompson sampling achieved **more total conversions** than fixed allocation.\n",
    "\n",
    "This is the essence of **regret minimization**:\n",
    "- Traditional A/B testing: \"Learn which is best\"\n",
    "- Thompson sampling: \"Maximize total conversions while learning\"\n",
    "\n",
    "---\n",
    "\n",
    "### 4. No Stopping Rule Needed\n",
    "\n",
    "Unlike NHST:\n",
    "- **No need to pre-compute sample size**\n",
    "- **No need to wait for significance**\n",
    "- **Can check results anytime** without \"p-hacking\"\n",
    "- **Algorithm keeps improving** the longer it runs\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding New Variants Dynamically\n",
    "\n",
    "One of Thompson sampling's greatest advantages: **new variants can enter at any time**.\n",
    "\n",
    "### How It Works\n",
    "\n",
    "1. **New variant arrives**: Initialize with prior Beta(1, 1) (or weakly informative prior)\n",
    "2. **Immediately participates**: Competes in sampling with existing variants\n",
    "3. **Gets explored**: Wide posterior ‚Üí sometimes samples high ‚Üí gets traffic\n",
    "4. **Proves itself or fades**: Good variants get more traffic; bad ones get less\n",
    "\n",
    "No need to:\n",
    "- Stop the test\n",
    "- Redistribute traffic manually\n",
    "- Recalculate sample sizes\n",
    "- Worry about multiple comparisons\n",
    "\n",
    "### Example: Adding Variant D Mid-Test\n",
    "\n",
    "Suppose after 2000 users, product team creates **variant D** with 72% conversion (better than all existing variants).\n",
    "\n",
    "What happens:\n",
    "1. **D starts with Beta(1, 1)** ‚Äî knows nothing\n",
    "2. **D gets explored** ‚Äî wide posterior sometimes samples high\n",
    "3. **D converts well** ‚Äî posterior narrows around 72%\n",
    "4. **D wins most samples** ‚Äî traffic shifts to D\n",
    "5. **A/B/C fade out** ‚Äî naturally get less traffic\n",
    "\n",
    "Let's simulate this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def thompson_sampling_with_new_variant(true_rates, n_users_before, new_variant_rate, n_users_after):\n",
    "    \"\"\"\n",
    "    Simulate Thompson sampling where a new variant is added mid-experiment.\n",
    "    \"\"\"\n",
    "    variants = list(true_rates.keys())\n",
    "    \n",
    "    # Initialize posteriors\n",
    "    alpha = {v: 1 for v in variants}\n",
    "    beta = {v: 1 for v in variants}\n",
    "    \n",
    "    n_shown = {v: 0 for v in variants}\n",
    "    n_converted = {v: 0 for v in variants}\n",
    "    \n",
    "    history = {'user': [], 'traffic_A': [], 'traffic_B': [], 'traffic_C': [], 'traffic_D': []}\n",
    "    \n",
    "    # Phase 1: Before new variant\n",
    "    print(f\"Phase 1: Running with variants {variants}...\")\n",
    "    for user_id in range(n_users_before):\n",
    "        samples = {v: np.random.beta(alpha[v], beta[v]) for v in variants}\n",
    "        chosen = max(samples, key=samples.get)\n",
    "        converted = np.random.random() < true_rates[chosen]\n",
    "        \n",
    "        alpha[chosen] += converted\n",
    "        beta[chosen] += (1 - converted)\n",
    "        n_shown[chosen] += 1\n",
    "        n_converted[chosen] += converted\n",
    "    \n",
    "    print(f\"After {n_users_before} users:\")\n",
    "    for v in variants:\n",
    "        pct = 100 * n_shown[v] / n_users_before\n",
    "        print(f\"  {v}: {pct:.1f}% traffic, Beta({alpha[v]:.0f}, {beta[v]:.0f})\")\n",
    "    \n",
    "    # Phase 2: Add new variant D\n",
    "    print(f\"\\nüÜï Adding new variant D with true rate {new_variant_rate*100:.1f}%...\\n\")\n",
    "    true_rates['D'] = new_variant_rate\n",
    "    variants.append('D')\n",
    "    alpha['D'] = 1  # Start with uninformative prior\n",
    "    beta['D'] = 1\n",
    "    n_shown['D'] = 0\n",
    "    n_converted['D'] = 0\n",
    "    \n",
    "    # Continue experiment\n",
    "    total_users = n_users_before\n",
    "    for user_id in range(n_users_after):\n",
    "        samples = {v: np.random.beta(alpha[v], beta[v]) for v in variants}\n",
    "        chosen = max(samples, key=samples.get)\n",
    "        converted = np.random.random() < true_rates[chosen]\n",
    "        \n",
    "        alpha[chosen] += converted\n",
    "        beta[chosen] += (1 - converted)\n",
    "        n_shown[chosen] += 1\n",
    "        n_converted[chosen] += converted\n",
    "        total_users += 1\n",
    "        \n",
    "        # Track traffic allocation every 50 users\n",
    "        if user_id % 50 == 0:\n",
    "            history['user'].append(total_users)\n",
    "            for v in ['A', 'B', 'C', 'D']:\n",
    "                if v in n_shown:\n",
    "                    history[f'traffic_{v}'].append(100 * n_shown[v] / total_users)\n",
    "                else:\n",
    "                    history[f'traffic_{v}'].append(0)\n",
    "    \n",
    "    print(f\"\\nAfter {total_users} total users:\")\n",
    "    for v in variants:\n",
    "        pct = 100 * n_shown[v] / total_users\n",
    "        print(f\"  {v}: {pct:.1f}% traffic, Beta({alpha[v]:.0f}, {beta[v]:.0f})\")\n",
    "    \n",
    "    return history, n_shown, total_users\n",
    "\n",
    "# Run simulation\n",
    "true_rates_initial = {'A': 0.7016, 'B': 0.6824, 'C': 0.6903}\n",
    "history, n_shown, total = thompson_sampling_with_new_variant(\n",
    "    true_rates_initial.copy(), \n",
    "    n_users_before=2000, \n",
    "    new_variant_rate=0.72,  # D is better than A!\n",
    "    n_users_after=3000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize traffic allocation over time\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "ax.plot(history['user'], history['traffic_A'], label='Variant A', linewidth=2, color='#2ecc71')\n",
    "ax.plot(history['user'], history['traffic_B'], label='Variant B', linewidth=2, color='#e74c3c')\n",
    "ax.plot(history['user'], history['traffic_C'], label='Variant C', linewidth=2, color='#3498db')\n",
    "ax.plot(history['user'], history['traffic_D'], label='Variant D (new)', linewidth=2, color='#f39c12', linestyle='--')\n",
    "\n",
    "ax.axvline(x=2000, color='gray', linestyle=':', linewidth=2, alpha=0.7, label='D added')\n",
    "\n",
    "ax.set_xlabel('Number of Users', fontsize=12)\n",
    "ax.set_ylabel('Traffic Allocation (%)', fontsize=12)\n",
    "ax.set_title('Thompson Sampling: Dynamic Traffic Allocation with New Variant', fontsize=14, fontweight='bold')\n",
    "ax.legend(loc='right', fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_ylim(0, 80)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä Key Observations:\")\n",
    "print(\"  1. Before user 2000: A gets most traffic (it's the best)\")\n",
    "print(\"  2. At user 2000: D enters with uninformative prior\")\n",
    "print(\"  3. D gets explored: Wide posterior ‚Üí sometimes samples high\")\n",
    "print(\"  4. D proves superior: Converts at 72% ‚Üí posterior narrows\")\n",
    "print(\"  5. Traffic shifts to D: Algorithm automatically reallocates\")\n",
    "print(\"  6. A/B/C fade out: Naturally get less traffic as D dominates\")\n",
    "print(\"\\n‚úì NO manual intervention needed ‚Äî algorithm adapts automatically!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Practical Implementation Considerations\n",
    "\n",
    "### 1. Choosing Priors\n",
    "\n",
    "**Non-informative**: Beta(1, 1)\n",
    "- Use when you truly know nothing\n",
    "- Allows maximum influence from data\n",
    "- Good for fair comparison of new variants\n",
    "\n",
    "**Weakly informative**: Beta($\\alpha_0$, $\\beta_0$) centered on control rate\n",
    "- Use when variants should be \"around\" control performance\n",
    "- Faster convergence\n",
    "- Still allows data to dominate\n",
    "\n",
    "**Rule of thumb**: $\\alpha_0 + \\beta_0 \\approx 10-20$ for weak prior strength\n",
    "\n",
    "---\n",
    "\n",
    "### 2. When to Stop\n",
    "\n",
    "Unlike NHST, Thompson sampling has **no fixed stopping rule**.\n",
    "\n",
    "Options:\n",
    "\n",
    "**Business threshold**: Stop when P(best variant is best) > 95%\n",
    "```python\n",
    "if prob_best > 0.95:\n",
    "    deploy_winner()\n",
    "```\n",
    "\n",
    "**Traffic concentration**: Stop when winner gets >80% of traffic\n",
    "```python\n",
    "if traffic_to_best / total_traffic > 0.80:\n",
    "    deploy_winner()\n",
    "```\n",
    "\n",
    "**Time limit**: Run for N days regardless (still gets benefits of dynamic allocation)\n",
    "\n",
    "**Never stop**: Keep running indefinitely as a self-optimizing system\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Implementation in Traffic Splitters\n",
    "\n",
    "**Centralized approach**:\n",
    "```python\n",
    "class ThompsonSamplingTrafficSplitter:\n",
    "    def __init__(self, variants):\n",
    "        self.variants = variants\n",
    "        self.alpha = {v: 1 for v in variants}\n",
    "        self.beta = {v: 1 for v in variants}\n",
    "    \n",
    "    def choose_variant(self):\n",
    "        \"\"\"Called for each user.\"\"\"\n",
    "        samples = {v: np.random.beta(self.alpha[v], self.beta[v]) \n",
    "                   for v in self.variants}\n",
    "        return max(samples, key=samples.get)\n",
    "    \n",
    "    def update(self, variant, converted):\n",
    "        \"\"\"Called after user outcome is observed.\"\"\"\n",
    "        self.alpha[variant] += converted\n",
    "        self.beta[variant] += (1 - converted)\n",
    "    \n",
    "    def add_variant(self, new_variant):\n",
    "        \"\"\"Add new variant dynamically.\"\"\"\n",
    "        self.variants.append(new_variant)\n",
    "        self.alpha[new_variant] = 1\n",
    "        self.beta[new_variant] = 1\n",
    "```\n",
    "\n",
    "**Distributed approach** (for high-scale systems):\n",
    "- Store (Œ±, Œ≤) parameters in distributed cache (Redis, etc.)\n",
    "- Each server samples locally\n",
    "- Batch updates to reduce contention\n",
    "- Acceptable to be slightly out-of-sync (algorithm is robust)\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Monitoring\n",
    "\n",
    "Track:\n",
    "- **Current traffic allocation** per variant\n",
    "- **Posterior means** (estimated conversion rates)\n",
    "- **Credible intervals** (uncertainty)\n",
    "- **P(variant is best)** for each variant\n",
    "- **Total conversions** and **regret**\n",
    "\n",
    "Alert if:\n",
    "- Traffic becomes too concentrated (>95% to one variant) before you're ready\n",
    "- Posteriors stop updating (suggests implementation bug)\n",
    "- Observed rates deviate significantly from posteriors (data quality issue)\n",
    "\n",
    "---\n",
    "\n",
    "### 5. A/A Testing\n",
    "\n",
    "Before deploying Thompson sampling in production:\n",
    "\n",
    "**Run A/A test**: Split traffic between two identical experiences\n",
    "- Should allocate ~50/50 in the long run\n",
    "- Should not confidently declare a winner\n",
    "- Validates implementation correctness\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary: From Bayesian Posteriors to Optimal Traffic Allocation\n",
    "\n",
    "### The Journey\n",
    "\n",
    "1. **Bayesian inference** gives us posterior distributions for conversion rates\n",
    "2. **Sampling from posteriors** naturally encodes exploration vs. exploitation\n",
    "3. **Thompson sampling** turns this into a simple, optimal traffic allocation algorithm\n",
    "4. **Dynamic reallocation** minimizes regret and maximizes total conversions\n",
    "5. **Continuous adaptation** allows adding/removing variants without restart\n",
    "\n",
    "---\n",
    "\n",
    "### Why Thompson Sampling is Superior\n",
    "\n",
    "| Aspect | Traditional A/B | Thompson Sampling |\n",
    "|--------|----------------|-------------------|\n",
    "| **Traffic allocation** | Fixed (e.g., 33/33/33) | Dynamic (adapts to performance) |\n",
    "| **Total conversions** | Suboptimal (wastes traffic) | Near-optimal (minimizes regret) |\n",
    "| **Time to decision** | Wait for significance | Continuous improvement |\n",
    "| **Adding variants** | Restart test | Add anytime |\n",
    "| **Removing variants** | Manual rebalance | Automatic fade-out |\n",
    "| **Multiple comparisons** | Need corrections | No problem |\n",
    "| **Stopping rule** | Pre-determined | Flexible |\n",
    "| **Implementation** | Complex statistics | 5 lines of code |\n",
    "\n",
    "---\n",
    "\n",
    "### When to Use Thompson Sampling\n",
    "\n",
    "‚úÖ **Perfect for**:\n",
    "- Product experimentation with multiple variants\n",
    "- Continuous optimization (content, recommendations, ads)\n",
    "- High-traffic scenarios (thousands of users per day)\n",
    "- Dynamic environments (variants added/removed frequently)\n",
    "- When you care about **total conversions**, not just identifying the winner\n",
    "\n",
    "‚ö†Ô∏è **Consider alternatives when**:\n",
    "- Very low traffic (<100 users per day) ‚Äî may be too slow\n",
    "- Regulatory requirements for fixed sample sizes (pharma, medical devices)\n",
    "- Need explainable p-values for stakeholders (though Bayesian probabilities are more interpretable)\n",
    "\n",
    "---\n",
    "\n",
    "### Implementation Checklist\n",
    "\n",
    "‚úì Choose appropriate priors (weakly informative recommended)  \n",
    "‚úì Implement core algorithm (choose, observe, update)  \n",
    "‚úì Add monitoring (traffic allocation, posteriors, probabilities)  \n",
    "‚úì Run A/A test to validate implementation  \n",
    "‚úì Define stopping criteria (business threshold, time limit, or continuous)  \n",
    "‚úì Plan for adding/removing variants  \n",
    "‚úì Document for stakeholders  \n",
    "\n",
    "---\n",
    "\n",
    "### The Bottom Line\n",
    "\n",
    "**Thompson sampling transforms Bayesian posteriors into a self-optimizing traffic splitter.**\n",
    "\n",
    "No complex statistics. No sample size calculations. No stopping rules. No multiple comparison corrections.\n",
    "\n",
    "Just:\n",
    "1. Sample\n",
    "2. Choose\n",
    "3. Observe\n",
    "4. Update\n",
    "5. Repeat\n",
    "\n",
    "**Mathematics meets elegance. Theory meets practice. Bayesian meets optimal.**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## Appendix: Real-World Implementation Considerations\n\n### Critical Assumptions to Revisit in Production\n\nThe simulation above makes several simplifying assumptions that **do not hold in real-world systems**. Deploying Thompson sampling without addressing these can lead to suboptimal performance or incorrect results.\n\n---\n\n### 1. The \"Immediate Feedback\" Assumption\n\n#### What the Simulation Assumes\n\nThe code above assumes **instant feedback**:\n```python\n# Step 1: Choose variant\nchosen = max(samples, key=samples.get)\n\n# Step 2: Show variant to user\nshow_variant_to_user(chosen)\n\n# Step 3: Observe outcome (IMMEDIATELY!)\nconverted = observe_outcome()\n\n# Step 4: Update posterior (with fresh data)\nalpha[chosen] += converted\nbeta[chosen] += (1 - converted)\n```\n\nThis implies that we know whether the user converted **before the next user arrives**.\n\n---\n\n#### Why This Matters\n\n**Real-world conversion delays**:\n- **E-commerce**: User adds to cart, may purchase hours/days later\n- **SaaS signup**: User signs up, may activate weeks later\n- **Content engagement**: User views article, may return to read later\n- **Mobile app install**: User clicks ad, may install the next day\n\n**The problem with high traffic**:\n\nIf you have **100 users/minute** and **1-hour conversion delay**:\n- You'll serve **6,000 users** before the **first feedback** arrives\n- All 6,000 decisions made with **stale priors** (Beta(1, 1))\n- Essentially **random traffic allocation** for the first hour\n- **Massive regret** from uniformed early decisions\n\n**Example**:\n```\nt=0:00  User 1 arrives ‚Üí Sample from Beta(1,1) for all variants ‚Üí Choose randomly\nt=0:01  User 2 arrives ‚Üí Sample from Beta(1,1) (no updates yet) ‚Üí Choose randomly\n...\nt=0:59  User 6000 arrives ‚Üí Sample from Beta(1,1) (still no feedback!)\nt=1:00  User 1's conversion finally observed ‚Üí First update to posteriors\nt=1:01  Users 6001+ now make slightly more informed decisions\n```\n\nFor the first hour, you have **no advantage over random allocation**.\n\n---\n\n#### The Correction: Batch Updates\n\nReal-world Thompson sampling implementations typically use **batched updates**:\n\n**Approach 1: Fixed time batches**\n```python\nclass BatchedThompsonSampling:\n    def __init__(self, batch_interval_minutes=60):\n        self.batch_interval = batch_interval_minutes\n        self.pending_observations = []\n        self.last_update_time = time.now()\n    \n    def choose_variant(self, user_id):\n        \"\"\"Choose variant for incoming user (no update yet).\"\"\"\n        samples = {v: np.random.beta(self.alpha[v], self.beta[v]) \n                   for v in self.variants}\n        chosen = max(samples, key=samples.get)\n        \n        # Store user assignment (will update later)\n        self.pending_observations.append({\n            'user_id': user_id,\n            'variant': chosen,\n            'timestamp': time.now(),\n            'converted': None  # Unknown yet\n        })\n        \n        return chosen\n    \n    def update_batch(self):\n        \"\"\"Called every batch_interval minutes.\"\"\"\n        # Fetch conversion data for pending observations\n        for obs in self.pending_observations:\n            converted = get_conversion_data(obs['user_id'])\n            if converted is not None:  # Conversion window closed\n                self.alpha[obs['variant']] += converted\n                self.beta[obs['variant']] += (1 - converted)\n                self.pending_observations.remove(obs)\n        \n        self.last_update_time = time.now()\n```\n\n**Trade-offs**:\n- ‚úÖ **Handles delayed conversions** properly\n- ‚úÖ **Reduces database load** (batch queries instead of individual lookups)\n- ‚úÖ **Scales to high traffic** (update priors hourly, not per-user)\n- ‚ö†Ô∏è **Slower learning** (priors update every hour, not every second)\n- ‚ö†Ô∏è **More \"wasted\" traffic** early on (stuck with stale priors longer)\n\n---\n\n**Approach 2: Pending observation tracking**\n\nFor conversions with variable delays (e.g., \"converted within 7 days\"):\n\n```python\nclass ThompsonSamplingWithPendingObs:\n    def __init__(self, conversion_window_days=7):\n        self.conversion_window = conversion_window_days\n        self.alpha = {v: 1 for v in variants}\n        self.beta = {v: 1 for v in variants}\n        self.pending = []  # Users within conversion window\n    \n    def choose_variant(self, user_id, timestamp):\n        \"\"\"Choose variant for user.\"\"\"\n        # First, update priors with resolved observations\n        self._update_resolved_observations(timestamp)\n        \n        # Then sample and choose\n        samples = {v: np.random.beta(self.alpha[v], self.beta[v]) \n                   for v in self.variants}\n        chosen = max(samples, key=samples.get)\n        \n        # Track pending observation\n        self.pending.append({\n            'user_id': user_id,\n            'variant': chosen,\n            'shown_at': timestamp,\n            'resolve_after': timestamp + timedelta(days=self.conversion_window)\n        })\n        \n        return chosen\n    \n    def _update_resolved_observations(self, current_time):\n        \"\"\"Move observations from pending to priors if conversion window closed.\"\"\"\n        resolved = [obs for obs in self.pending \n                    if current_time >= obs['resolve_after']]\n        \n        for obs in resolved:\n            converted = check_if_converted(obs['user_id'], obs['variant'])\n            self.alpha[obs['variant']] += converted\n            self.beta[obs['variant']] += (1 - converted)\n            self.pending.remove(obs)\n```\n\n**Trade-offs**:\n- ‚úÖ **Correct handling** of variable conversion windows\n- ‚úÖ **Updates as soon as conversions resolve**\n- ‚ö†Ô∏è **Requires tracking pending observations** (memory overhead)\n- ‚ö†Ô∏è **More complex implementation**\n\n---\n\n**Approach 3: Optimistic initialization**\n\nIf you know the approximate conversion rate range (e.g., from historical data):\n\n```python\n# Instead of uninformative Beta(1, 1)\n# Use weakly informative prior centered on control rate\nalpha_0 = 70  # Expected ~70% conversion\nbeta_0 = 30   # Expected ~30% non-conversion\n\n# Now early random exploration is less damaging\n# First users see approximately 70% conversion performance\n# Even before real feedback arrives\n```\n\n**Trade-offs**:\n- ‚úÖ **Reduces early regret** (better than random)\n- ‚úÖ **No complex pending-observation tracking**\n- ‚ö†Ô∏è **Requires domain knowledge** (historical conversion rates)\n- ‚ö†Ô∏è **Biases toward prior** (slower to detect if new variant is radically different)\n\n---\n\n#### Recommendation for Production\n\n**For high-traffic systems (>1000 users/hour)**:\n1. Use **batched updates** (every 10-60 minutes depending on conversion delay)\n2. Start with **weakly informative priors** (reduces early regret)\n3. Track **pending observations** separately (don't update priors until resolved)\n4. Monitor **\"stuck\" observations** (conversions that never resolve ‚Üí data quality issue)\n\n**For low-traffic systems (<100 users/hour)**:\n- Sequential updates may be acceptable\n- But still need to handle delayed conversions (wait for resolution before updating)\n\n---\n\n#### Key Takeaway\n\n**The simulation in this notebook is \"sequential\" and assumes immediate feedback.**\n\nIn real-world production:\n- Conversions are **delayed** (minutes to days)\n- Traffic is **high** (hundreds/thousands per minute)\n- Naive implementation = **random allocation** until first feedback\n- **Solution**: Batch updates + pending observation tracking + informative priors\n\n**Without addressing this**, Thompson sampling may perform **no better than random allocation** in the critical early phase of the experiment.\n\n---\n\n### 2. The \"No Stopping Rule\" Claim (Conceptual Precision)\n\n#### What the Notebook Claims\n\nFrom the Executive Summary:\n> \"No complex formulas, **no stopping rules**, no power calculations.\"\n\nFrom Key Insights:\n> \"**No Stopping Rule Needed**... Can check results anytime without p-hacking.\"\n\nThis sounds liberating ‚Äî no need to pre-determine when to stop!\n\n---\n\n#### The Nuance: It Depends on Your Goal\n\n**This is true IF your goal is optimization** (the bandit problem):\n- **Goal**: \"Maximize total conversions over the experiment duration\"\n- **Question**: \"Which variant should I show to the *next* user?\"\n- **Answer**: Run Thompson sampling indefinitely ‚Äî it's a **self-optimizing system**\n- **No stopping rule needed**: The algorithm keeps improving the longer it runs\n\n**This is FALSE if your goal is inference**:\n- **Goal**: \"Decide if variant B is better than variant A with 95% confidence\"\n- **Question**: \"Should I deploy B permanently and *delete A's code*?\"\n- **Answer**: You need a **decision rule** (effectively a stopping rule)\n\n---\n\n#### The Reality Check\n\nIf you want to **conclude** something like:\n\n> \"We are 95% confident that variant B has a higher conversion rate than variant A.\"\n\nThen you **ARE re-introducing a stopping rule**, just phrased differently:\n\n```python\n# This IS a stopping rule!\nif P(B is best | data) > 0.95:\n    stop_experiment()\n    deploy_variant_B_permanently()\n    delete_variant_A_code()\n```\n\n**Why?**\n- You're making a **binary decision** (keep B, discard A)\n- This is **inference**, not optimization\n- You need to decide when you have enough evidence\n\n---\n\n#### When \"No Stopping Rule\" Actually Applies\n\n**Continuous optimization scenarios**:\n\n**Example 1: Content recommendation system**\n```python\n# Never stop ‚Äî keep optimizing forever\nwhile True:\n    user = get_next_user()\n    variant = thompson_sampling.choose()\n    show_content(user, variant)\n    observe_and_update()\n```\n\nHere, Thompson sampling is **not trying to \"prove\" which variant is best**. It's just **allocating traffic to maximize total engagement**. Variants can come and go. No need to stop.\n\n**Example 2: Dynamic pricing**\n```python\n# Prices change over time, just keep optimizing\nwhile True:\n    customer = get_next_customer()\n    price = thompson_sampling.choose_price()\n    offer(customer, price)\n    observe_purchase_and_update()\n```\n\nNo stopping rule needed ‚Äî you're not trying to declare a winner, just maximize revenue.\n\n---\n\n#### When You DO Need a Stopping Rule\n\n**Inference scenarios**:\n\n**Example 1: Launching a new product design**\n- **Goal**: Decide whether to manufacture design B or stick with design A\n- **Need**: 95% confidence that B is better before committing to tooling/production\n- **Stopping rule**: When P(B > A | data) > 0.95\n\n**Example 2: Regulatory approval**\n- **Goal**: Prove new drug formulation is more effective\n- **Need**: Statistical evidence for regulatory submission\n- **Stopping rule**: Pre-registered sample size or Bayesian decision threshold\n\n**Example 3: Engineering resource allocation**\n- **Goal**: Decide which authentication method to support long-term\n- **Need**: High confidence before deprecating the other method\n- **Stopping rule**: When P(best is best | data) > 0.95 and observed for N days\n\n---\n\n#### What the Notebook SHOULD Say\n\nThe \"When to Stop\" section (under Practical Implementation) **does** acknowledge this:\n\n> **Business threshold**: Stop when P(best variant is best) > 95%\n\nThis is correct! But the Executive Summary's claim of \"no stopping rules\" is **slightly hyperbolic**.\n\n**More precise framing**:\n\n‚úÖ **Optimization goal**: No stopping rule needed ‚Äî run indefinitely  \n‚ö†Ô∏è **Inference goal**: You need a decision threshold (a form of stopping rule)  \n‚úÖ **No *pre-computed* stopping rule**: Unlike NHST, you don't need to calculate sample size upfront  \n‚úÖ **Flexible stopping**: You can check P(best | data) anytime without \"p-hacking\"  \n\n---\n\n#### Key Takeaway\n\n**\"No stopping rules\" is true for continuous optimization, but NOT for inference.**\n\nIf your goal is to:\n- **Maximize total conversions during the experiment** ‚Üí No stopping rule needed\n- **Decide which variant to keep permanently** ‚Üí You need a decision threshold\n\nThe beauty of Thompson sampling is:\n- **Optimization phase**: Minimizes regret automatically\n- **Inference phase**: Compute P(B > A | data) whenever you want (no p-hacking!)\n- **Combined**: You optimize *while* gathering evidence for inference\n\nBut don't confuse \"flexible stopping\" with \"no stopping rule needed for inference.\"\n\n---\n\n### 3. Non-Stationarity (The Fixed Conversion Rate Assumption)\n\n#### What the Simulation Assumes\n\nThe simulation uses **fixed true conversion rates**:\n\n```python\ntrue_rates = {\n    'A': 0.7016,  # Fixed forever\n    'B': 0.6824,  # Never changes\n    'C': 0.6903,  # Constant\n}\n\n# Users arrive, conversions observed, posteriors updated\n# But true_rates NEVER CHANGE\n```\n\nThis assumes conversion rates are **stationary** (constant over time).\n\n---\n\n#### Why This is Unrealistic\n\n**Real-world conversion rates drift**:\n\n**Time-of-day effects**:\n- Morning users (commuters) ‚Üí lower conversion\n- Lunch users (browsing at desk) ‚Üí higher conversion\n- Evening users (leisurely shopping) ‚Üí medium conversion\n\n**Day-of-week effects**:\n- Weekday traffic ‚Üí work-related conversions (higher for B2B)\n- Weekend traffic ‚Üí leisure conversions (higher for e-commerce)\n\n**Seasonality**:\n- Holiday season ‚Üí higher conversion rates\n- Back-to-school ‚Üí different product preferences\n- Summer slump ‚Üí lower engagement\n\n**External events**:\n- Competitor launches sale ‚Üí your conversions drop\n- Viral social media post ‚Üí sudden traffic surge with different behavior\n- Economic downturn ‚Üí conversion rates shift\n\n**Product evolution**:\n- Variant A updated with bug fix ‚Üí conversion rate improves\n- Marketing campaign mentions variant C ‚Üí its appeal changes\n\n---\n\n#### The Problem with Standard Bayesian Updates\n\nStandard Thompson sampling **remembers all history**:\n\n$$\n\\alpha_i = \\alpha_0 + \\sum_{\\text{all time}} \\text{conversions}_i\n$$\n\n$$\n\\beta_i = \\beta_0 + \\sum_{\\text{all time}} \\text{non-conversions}_i\n$$\n\nAfter many observations:\n- $\\alpha_i$ and $\\beta_i$ grow to **hundreds or thousands**\n- Posterior becomes **very narrow** (low variance)\n- Algorithm becomes **highly confident** about old data\n\n**What happens when conversion rates drift?**\n\n**Example**: Variant A's true rate was 70%, now it's 65% (due to competitor)\n\n```\nDay 1-30:  A converts at 70% ‚Üí Posterior: Beta(2100, 900) ‚Üí mean ‚âà 70%\nDay 31:    Competitor launches, A now converts at 65%\nDay 31-35: New data comes in at 65%, but...\n           Posterior: Beta(2100 + 50, 900 + 27) ‚Üí mean ‚âà 69.7%\n           \nStill thinks A is ~70% because old data dominates!\n```\n\nThe posterior is **sluggish** ‚Äî it takes a long time to react to the new reality because:\n- 2100 old conversions \"vote\" for 70%\n- 50 new conversions \"vote\" for 65%\n- Old data wins due to sheer volume\n\n---\n\n#### The Consequence: Stuck in the Past\n\n**Problem 1: Can't detect new winners**\n- Variant B's true rate improves from 68% to 72% (now better than A)\n- But algorithm is \"confident\" A is best (based on old data)\n- Takes thousands of users to shift belief\n\n**Problem 2: Wastes traffic on degraded variants**\n- Variant A's true rate drops from 70% to 60% (now worse than C)\n- Algorithm still allocates 60% of traffic to A (based on historical performance)\n- Massive regret while slowly updating belief\n\n**Problem 3: \"Frozen\" traffic allocation**\n- After 100,000 users, posteriors are extremely narrow\n- Traffic allocation becomes nearly deterministic\n- Little exploration ‚Üí can't adapt to changes\n\n---\n\n#### The Fix: Discounting Old Data\n\nProduction Thompson sampling systems use **forgetting mechanisms** to stay agile:\n\n---\n\n**Approach 1: Exponential decay (discount factor)**\n\n```python\nclass ThompsonSamplingWithDecay:\n    def __init__(self, decay_rate=0.99):\n        self.decay_rate = decay_rate  # 0.99 = remember 99% of history\n        self.alpha = {v: 1 for v in variants}\n        self.beta = {v: 1 for v in variants}\n    \n    def update(self, variant, converted):\n        \"\"\"Update with decay applied to old data.\"\"\"\n        # Decay old beliefs toward prior\n        self.alpha[variant] = 1 + (self.alpha[variant] - 1) * self.decay_rate\n        self.beta[variant] = 1 + (self.beta[variant] - 1) * self.decay_rate\n        \n        # Add new observation\n        self.alpha[variant] += converted\n        self.beta[variant] += (1 - converted)\n```\n\n**Effect**:\n- Recent data has **more weight** than old data\n- Posteriors stay **narrower than uniform**, but don't grow indefinitely\n- Algorithm remains **responsive** to drift\n\n**Trade-off**:\n- ‚úÖ Adapts to changing conversion rates\n- ‚ö†Ô∏è Forgets valuable historical information\n- ‚ö†Ô∏è Requires tuning decay_rate (0.99 = slow decay, 0.90 = fast decay)\n\n---\n\n**Approach 2: Sliding window**\n\n```python\nclass ThompsonSamplingWithWindow:\n    def __init__(self, window_size=10000):\n        self.window_size = window_size\n        self.observations = {v: deque(maxlen=window_size) for v in variants}\n        self.alpha = {v: 1 for v in variants}\n        self.beta = {v: 1 for v in variants}\n    \n    def update(self, variant, converted):\n        \"\"\"Only count recent observations.\"\"\"\n        self.observations[variant].append(converted)\n        \n        # Recompute from sliding window\n        conversions = sum(self.observations[variant])\n        non_conversions = len(self.observations[variant]) - conversions\n        \n        self.alpha[variant] = 1 + conversions\n        self.beta[variant] = 1 + non_conversions\n```\n\n**Effect**:\n- Only the **last N observations** influence the posterior\n- Old data completely forgotten after N new users\n- Algorithm stays **agile**\n\n**Trade-off**:\n- ‚úÖ Clear semantics (only last N users matter)\n- ‚úÖ No tuning required (just choose window size)\n- ‚ö†Ô∏è Higher memory overhead (store recent observations)\n- ‚ö†Ô∏è Sudden \"cliff\" when old observation exits window\n\n---\n\n**Approach 3: Time-based windowing**\n\n```python\nclass ThompsonSamplingWithTimeWindow:\n    def __init__(self, window_days=30):\n        self.window_days = window_days\n        self.observations = {v: [] for v in variants}\n        self.alpha = {v: 1 for v in variants}\n        self.beta = {v: 1 for v in variants}\n    \n    def update(self, variant, converted, timestamp):\n        \"\"\"Only count observations from last N days.\"\"\"\n        cutoff = timestamp - timedelta(days=self.window_days)\n        \n        # Store observation with timestamp\n        self.observations[variant].append((timestamp, converted))\n        \n        # Recompute from time window\n        recent = [(ts, conv) for ts, conv in self.observations[variant] \n                  if ts >= cutoff]\n        conversions = sum(conv for ts, conv in recent)\n        non_conversions = len(recent) - conversions\n        \n        self.alpha[variant] = 1 + conversions\n        self.beta[variant] = 1 + non_conversions\n```\n\n**Effect**:\n- Only observations from **last N days** count\n- Naturally handles varying traffic (weekday vs weekend)\n- Algorithm adapts to **seasonal patterns**\n\n**Trade-off**:\n- ‚úÖ Semantically clear (recent behavior matters)\n- ‚úÖ Handles non-uniform traffic patterns\n- ‚ö†Ô∏è Requires timestamp tracking\n- ‚ö†Ô∏è Window size needs domain knowledge (30 days? 7 days? 90 days?)\n\n---\n\n#### Recommendation for Production\n\n**For stationary environments** (conversion rates don't change):\n- Use **standard Thompson sampling** (accumulate all data)\n- Simpler, no tuning needed\n\n**For non-stationary environments** (rates drift over time):\n- Use **exponential decay** (good default: decay_rate=0.99)\n- Or use **sliding window** (e.g., last 10,000 users or 30 days)\n- Monitor posterior variance ‚Äî if it shrinks too much, add decay\n\n**For highly dynamic environments** (A/B testing on news sites, ad campaigns):\n- Use **aggressive discounting** (decay_rate=0.90) or **short windows** (7 days)\n- Prioritize agility over long-term memory\n\n---\n\n#### Key Takeaway\n\n**The simulation assumes conversion rates are fixed forever ‚Äî they are NOT.**\n\nIn production:\n- **Conversion rates drift** due to time-of-day, seasonality, competition, etc.\n- **Standard Bayesian updates remember all history** (Œ±, Œ≤ ‚Üí ‚àû)\n- **Posteriors become too confident** and **sluggish to adapt**\n- **Solution**: Discount old data via decay factors or sliding windows\n\n**Without addressing this**, Thompson sampling will:\n- Keep allocating traffic to variants that *used to be good* but aren't anymore\n- Fail to detect variants that *became good* recently\n- Suffer high regret in non-stationary environments\n\n---"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finance",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}