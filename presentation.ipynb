{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.stats import beta as beta_dist\n",
    "from plotting_utils import plot_gaussian_hypothesis_test\n",
    "from plotting_utils import plot_type_ii_error_analysis, plot_beta_prior_comparison, plot_prior_vs_posterior\n",
    "from plotting_utils import plot_informative_prior_posterior_comparison, plot_weakly_informative_prior_with_variants\n",
    "from plotting_utils import plot_multiple_posteriors_comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<style>\n",
    ".reveal h1 { font-size: 1.8em; color: #4a90d9; }\n",
    ".reveal h2 { font-size: 1.4em; color: #4a90d9; }\n",
    ".reveal h3 { font-size: 1.1em; color: #4a90d9; }\n",
    ".reveal { color: #333; }\n",
    "</style>\n",
    "\n",
    "# From Manual Bayesian A/B Tests to Continuous Thompson Sampling\n",
    "\n",
    "**A Post Mortem of our Passkeys A/B tests and a proposal for automated approaches**\n",
    "\n",
    "<br><br><br><br>\n",
    "\n",
    "<p style=\"font-size: 0.6em; color: #666; line-height: 1.6;\">\n",
    "All the notebooks with running code can be cloned from\n",
    "<br><a href=\"https://github.com/alaindemour/ABtest_methodologies\" style=\"color: #4a90d9;\">https://github.com/alaindemour/ABtest_methodologies</a>\n",
    "<br>Created with the help of Claude Sonnet 4.6\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Presentation Overview\n",
    "\n",
    "1. **Executive Summary** Business Problem and Solution\n",
    "2. **Classical vs. Bayesian Statistics**\n",
    "3. **Why Bayesian is Better** for CX / pricing A/B tests\n",
    "4. **Non-Inferiority Test** â€” NHST fails, Bayesian succeeds\n",
    "5. **Select Best Variant** â€” direct probability\n",
    "6. **Corporate Iteration Speed** â€” the deployment bottleneck\n",
    "7. **Thompson Sampling** â€” the fully automated solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Reminder: Our Experiment Setup\n",
    "- **Variant A**: Combo password+passkey page with passkey creation as a default on ğŸ¯\n",
    "- **Variant B**: Combo password_passkey page with passkey creation as a default off\n",
    "- **Variant C**: Multi Pages, password completely separate from passkeys, with step by step instructions\n",
    "- **Control Group**: Legacy flow with no passkey creation offered\n",
    "\n",
    "For Amazon linking the KPI was **maximum number of passkey creations** to improve gating rate while **avoiding any degradation** of the existing\n",
    "linking rate\n",
    "\n",
    "Not the purpose of the this presntation but A significanlty better for true end to end sucess ratio, C better for the passkey creation step in isolation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Business Problem\n",
    "We would like to **experiment with CX often**, test **a large number of variants**, get results **within weeks** and **iterate quickly** (e.g. \"fail early\")\n",
    "\n",
    "## Experiment Design Reality\n",
    "Product, engineering, DCE, legal **haggled for months** on design and copy to get their **preferred** ideas in the **only 3** variants we could realistically launch, variants were **stakeholder compromises** to fit 3 options, not what we really wanted to test. That's a reality of the corporate world we have to accept.\n",
    " \n",
    "## Real-World Timeline\n",
    "\n",
    "| Date | Event |\n",
    "|------|-------|\n",
    "| **Oct** | Bug at launch, variant C gets all the traffic, missing control group |\n",
    "| **Early Nov** | Variant A wins with >90% probability â€” we know |\n",
    "| **Mid Nov** | Amazon release freeze (Black Friday) |\n",
    "| **Late Nov** | Release issues, more rollbacks |\n",
    "| **December** | Digital Channel release freeze, holiday delays |\n",
    "| **January** | Winner (variant A) finally ramped up |\n",
    "\n",
    "**~3 months** from \"we know\" to \"users benefit\" and next iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Reframing of the Problem: The Multi-Armed Bandit Framework\n",
    "One of the most famous problems in computer science (and life): the **Dilemma** â€” Explore (try machines) vs. Exploit (play the best)\n",
    "\n",
    "<div style=\"display: flex; align-items: center; gap: 40px;\">\n",
    "<div style=\"flex: 1;\">\n",
    "\n",
    "**Casino analogy**: K slot machines, unknown payouts, limited budget.\n",
    "\n",
    "| Casino | A/B Testing |\n",
    "|--------|-------------|\n",
    "| Slot machines | Variants |\n",
    "| Pull lever | Show variant |\n",
    "| Payout | User converts |\n",
    "\n",
    "\n",
    "</div>\n",
    "<div style=\"flex: 0 0 auto; text-align: center;\">\n",
    "<img src=\"images/multi_armed_bandit.jpg\" style=\"max-height: 320px; border-radius: 8px; box-shadow: 0 4px 12px rgba(0,0,0,0.15);\">\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## An Optimal Solution: Thompson Sampling\n",
    "\n",
    "- Can run a **massive number of variants** in parallel\n",
    "- Completely algorithmic and adaptive: **no release process** or anything manual involved\n",
    "- Mathematically proven to be **optimal**: converges the fastest to the best variant\n",
    "- Allows dynamic addition or removal of any number of variants, **can be always on**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Part 2: Classical vs. Bayesian Statistics\n",
    "\n",
    "Caveat: once you have millions of data points **none of this matters**; statistical inference is useful when you need to make decisions based on small samples and iterate quickly\n",
    "\n",
    "## The Fundamental Questions\n",
    "\n",
    "Classical statistics a.k.a. Frequentist uses a methodology called Null Hypothesis Significance Testing (NHST). If you hear **p-values** or **confidence intervals**, **Null Hypothesis** or **this experiment is underpowered**, it is NHST. Bayesian approaches directly compute precise probabilities for **all the possible hypotheses**, not just a single $H_0$.\n",
    "\n",
    "| Framework | Question | Notation |\n",
    "|-----------|----------|----------|\n",
    "| **NHST** | \"How likely is my observation (a.k.a. sample a.k.a data), assuming $H_0$?\" | p(data \\| Hypothesis) |\n",
    "| **Bayesian** | \"What is the precise probability of all hypotheses, given the observation?\" | p(Hypothesis \\| data) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## NHST in a Nutshell\n",
    "\n",
    "1. Assume a so called **Null Hypothesis** $H_0$ which is typically what you don't want to be true e.g. **the new drug has no effect** or **the new passkey creation UX degrades conversion**\n",
    "2. Compute a \"test statistic\" from the observed data; in this presentation it is a mean but can be any statistical measure\n",
    "3. If result is \"unlikely enough\" (p-value < 0.05), reject $H_0$\n",
    "\n",
    "### Key Caveats\n",
    "\n",
    "- Rejecting $H_0$ does **not** prove the alternative\n",
    "- The 5% threshold is a **convention**, not a law of nature\n",
    "- No quantified probability of being correct â€” just \"unlikely\" or \"not unlikely\"\n",
    "- The math involved requires large samples for significance\n",
    "- The math does not \"compose\", **it cannot implement the Thompson Sampling Algorithm which is iterative**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Bayesian in a Nutshell\n",
    "\n",
    "1. Pick a **prior belief** distribution for the measure we are interested in (conventionally noted as $\\theta$ and also called \"the parameter\"), the parameter is how we represent the various hypotheses e.g. $\\theta$ = conversion rate\n",
    "2. Observe data\n",
    "3. Apply **Bayes' theorem** â†’ get **posterior belief**\n",
    "\n",
    "$$\\boxed{P(\\theta \\mid \\text{data}) = \\frac{P(\\text{data} \\mid \\theta) \\cdot P(\\theta)}{P(\\text{data})}}$$\n",
    "\n",
    "âœ… 4. The Posterior belief can become the prior belief for the next update, that the **key property** of the Bayesian update which support Thompson sampling\n",
    "\n",
    "Full probability distribution â€” compute anything you need at any time during the experiment:\n",
    "point estimates, credible intervals, P(better than threshold), expected values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# What is a Probability Distribution?\n",
    "from scipy.stats import beta as beta_dist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "# Beta(9, 4): mean â‰ˆ 0.69 â€” same center, but wider spread than a large-sample posterior\n",
    "a, b = 9, 4\n",
    "x = np.linspace(0, 1, 500)\n",
    "y = beta_dist.pdf(x, a, b)\n",
    "\n",
    "# Full distribution curve over the complete [0, 1] domain\n",
    "ax.plot(x, y, 'k-', lw=2.5)\n",
    "\n",
    "# Shade the interval [0.70, 0.80]\n",
    "lo, hi = 0.70, 0.80\n",
    "mask = (x >= lo) & (x <= hi)\n",
    "prob = beta_dist.cdf(hi, a, b) - beta_dist.cdf(lo, a, b)\n",
    "ax.fill_between(x[mask], y[mask], alpha=0.35, color='#4a90d9',\n",
    "                label=f'P({lo:.0%} < conversion rate < {hi:.0%}) = {prob:.1%}')\n",
    "\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_xlabel('Conversion Rate', fontsize=13)\n",
    "ax.set_ylabel('Probability Density', fontsize=13)\n",
    "ax.set_title('What is a Probability Distribution?\\n'\n",
    "             'The shaded area = probability that the true conversion rate is in [70%, 80%]',\n",
    "             fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=11, loc='upper left')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Some Math: The Beta Probability Distribution\n",
    "\n",
    "<div style=\"display: flex; align-items: center; gap: 40px;\">\n",
    "<div style=\"flex: 1;\">\n",
    "\n",
    "- Models a **probability** (values in [0, 1])\n",
    "- Controlled by two parameters Î±, Î²\n",
    "- **Î± âˆ’ 1** = prior successes, **Î² âˆ’ 1** = prior failures\n",
    "- As data accumulates, the distribution **narrows** (more certainty)\n",
    "- Perfect for modeling conversion rates\n",
    "\n",
    "$$\\text{Beta}(x; \\alpha, \\beta) = \\frac{x^{\\alpha-1}(1-x)^{\\beta-1}}{\\int_0^1 t^{\\alpha-1}(1-t)^{\\beta-1}\\,dt}$$\n",
    "\n",
    "</div>\n",
    "<div style=\"flex: 0 0 auto; text-align: center;\">\n",
    "<img src=\"images/PDF_of_the_Beta_distribution.gif\" style=\"max-height: 320px; border-radius: 8px; box-shadow: 0 4px 12px rgba(0,0,0,0.15);\" alt=\"Beta distribution animation\">\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Plot comparison of different Beta prior distributions\n",
    "fig, axes = plot_beta_prior_comparison()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Bayesian Update: weakly informative prior â†’ posterior after moderate data\n",
    "# Prior: Beta(2, 2) â€” weakly informative, spread across full [0,1]\n",
    "# Data: 12 successes in 20 trials (60% rate)\n",
    "# Posterior: Beta(14, 10) â€” shifted toward 0.6 but still broad\n",
    "alpha_prior, beta_prior = 2, 2\n",
    "n_obs, k_obs = 20, 12\n",
    "alpha_post = alpha_prior + k_obs\n",
    "beta_post = beta_prior + (n_obs - k_obs)\n",
    "\n",
    "fig, ax, _, _ = plot_informative_prior_posterior_comparison(\n",
    "    alpha_prior=alpha_prior,\n",
    "    beta_prior=beta_prior,\n",
    "    alpha_posterior=alpha_post,\n",
    "    beta_posterior=beta_post,\n",
    "    x_limits=(0, 1)\n",
    ")\n",
    "print(f\"Prior: Beta({alpha_prior},{beta_prior}) â€” mean={alpha_prior/(alpha_prior+beta_prior):.0%}\")\n",
    "print(f\"Data: {k_obs} successes in {n_obs} trials\")\n",
    "print(f\"Posterior: Beta({alpha_post},{beta_post}) â€” mean={alpha_post/(alpha_post+beta_post):.0%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Part 3: Why Bayesian is Better\n",
    "\n",
    "## NHST Problems for Product A/B Tests\n",
    "\n",
    "| Problem | Impact |\n",
    "|---|---|\n",
    "| **Small samples** | At launch, n=150 per variant. NHST: \"inconclusive.\" |\n",
    "| **p-value hacking** | Can't peek at results without inflating false positives |\n",
    "| **Unbalanced samples** | 7,000 control vs. 150 variant â€” NHST loses power |\n",
    "| **Binary output** | \"Reject\" or \"fail to reject\" â€” no probabilities |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Where Bayesian Excels\n",
    "\n",
    "| Advantage | Detail |\n",
    "|---|---|\n",
    "| **Small samples** | Prior knowledge + data = meaningful conclusions |\n",
    "| **Unbalanced allocation** | Each variant analyzed independently |\n",
    "| **Many variants** | No multiple comparison penalties |\n",
    "| **Actionable output** | \"47% chance B is best\" â€” not just reject/fail |\n",
    "| **Continuous monitoring** | Check anytime, no p-hacking concerns |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Fun Fact: FDA Embraces Bayesian (January 2026)\n",
    "\n",
    "> The FDA issued draft guidance: **\"Use of Bayesian Methodology in Clinical Trials of Drugs and Biological Products\"**\n",
    "\n",
    "https://www.fda.gov/regulatory-information/search-fda-guidance-documents/use-bayesian-methodology-clinical-trials-drug-and-biological-products\n",
    "\n",
    "If the most conservative regulator in the world is adopting Bayesian methods, the case for product A/B testing is even stronger."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Part 4: Non-Inferiority Test for Amazon Linking\n",
    "\n",
    "## The Setup\n",
    "\n",
    "- Existing flow: **~71% completion rate**\n",
    "- Adding passkey creation (extra pages/clicks)\n",
    "- **Question**: Does the new experience cause unacceptable degradation?\n",
    "- **Non-inferiority margin**: $\\epsilon$ = 2%\n",
    "\n",
    "| Group | Sample size | Conversion rate |\n",
    "|-------|-----------|----------------|\n",
    "| Control | 32,106 | 70.9% |\n",
    "| Variant A | 4,625 | 70.1% |\n",
    "| Variant B | 2,100 | 68.2% |\n",
    "| Variant C | 2,022 | 69.0% |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm, beta as beta_dist\n",
    "\n",
    "# --- Experiment Data ---\n",
    "nC = 32106\n",
    "xC = 22772\n",
    "control_rate = xC / nC\n",
    "\n",
    "variants = {\n",
    "    'A': {'n': 4625, 'x': 3244},\n",
    "    'B': {'n': 2100, 'x': 1433},\n",
    "    'C': {'n': 2022, 'x': 1396}\n",
    "}\n",
    "\n",
    "epsilon = 0.02  # 2% non-inferiority margin\n",
    "\n",
    "print(f\"Control: n={nC:,}, rate={control_rate:.2%}\")\n",
    "for name, d in variants.items():\n",
    "    r = d['x'] / d['n']\n",
    "    print(f\"Variant {name}: n={d['n']:,}, rate={r:.2%}\")\n",
    "print(f\"\\nNon-inferiority margin (epsilon): {epsilon:.0%}\")\n",
    "print(f\"Non-inferiority threshold: {control_rate - epsilon:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## NHST Result: Inconclusive\n",
    "\n",
    "**p-value ~ 0.45** (45%) â€” very far from the 5% threshold\n",
    "\n",
    "NHST says: \"We can't say anything.\"\n",
    "\n",
    "The test is **severely underpowered** with a sample of n=2,022."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# NHST non-inferiority test on Variant C\n",
    "nX = variants['C']['n']\n",
    "xX = variants['C']['x']\n",
    "hatpC = xC / nC\n",
    "hatpA = xX / nX\n",
    "hatDelta = hatpA - hatpC\n",
    "\n",
    "# Unpooled SE (appropriate for non-inferiority)\n",
    "SE = np.sqrt(hatpC * (1 - hatpC) / nC + hatpA * (1 - hatpA) / nX)\n",
    "mu_H0 = -epsilon\n",
    "\n",
    "# p-value: right tail P(Delta >= observed | H0)\n",
    "p_value = norm.sf(hatDelta, loc=mu_H0, scale=SE)\n",
    "\n",
    "# Power analysis\n",
    "pooled_p = (xC + xX) / (nC + nX)\n",
    "SE_H1 = np.sqrt(pooled_p * (1 - pooled_p) * (1/nC + 1/nX))\n",
    "critical_value = norm.isf(0.05, loc=mu_H0, scale=SE)\n",
    "power = 1 - norm.cdf(critical_value, loc=0, scale=SE_H1)\n",
    "\n",
    "print(\"NHST Non-Inferiority Test (Variant C)\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Observed difference: {hatDelta:.4f}\")\n",
    "print(f\"Standard error: {SE:.4f}\")\n",
    "print(f\"p-value: {p_value:.4f}\")\n",
    "print(f\"Power: {power:.1%}\")\n",
    "print()\n",
    "if p_value <= 0.05:\n",
    "    print(\"Result: REJECT H0 â€” non-inferiority established\")\n",
    "else:\n",
    "    print(\"Result: FAIL TO REJECT â€” inconclusive\")\n",
    "    print(f\"  (Power is only {power:.1%} â€” test is severely underpowered)\")\n",
    "    print(f\"  NHST cannot help us with n={nX} for this variant.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Bayesian: Actionable Answer\n",
    "\n",
    "<!-- **Weakly informative prior** centered on expected performance:\n",
    "\n",
    "$$\\text{Beta}(\\alpha_0, \\beta_0) + \\text{Data} \\Rightarrow \\text{Beta}(\\alpha_0 + k, \\; \\beta_0 + n - k)$$\n",
    "\n",
    "Then directly compute: $P(\\text{variant} > \\text{control} - \\epsilon)$ -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "from bayesian import test_non_inferiority_weakly_informative\n",
    "from plotting_utils import plot_weakly_informative_prior_with_variants\n",
    "\n",
    "# Run Bayesian non-inferiority test on all variants\n",
    "expected_degradation = 0.01  # Domain knowledge: adding clicks may degrade by ~1%\n",
    "\n",
    "results_ni = test_non_inferiority_weakly_informative(\n",
    "    n_control=nC,\n",
    "    x_control=xC,\n",
    "    variants_data=variants,\n",
    "    epsilon=epsilon,\n",
    "    expected_degradation=expected_degradation,\n",
    "    alpha_prior_strength=20,  # Weak prior (high entropy)\n",
    "    threshold=0.95\n",
    ")\n",
    "\n",
    "print(\"Bayesian Non-Inferiority Test Results\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Prior centered at: {control_rate - expected_degradation:.2%}\")\n",
    "print(f\"Test threshold: {control_rate - epsilon:.2%}\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "for name, res in results_ni.items():\n",
    "    status = \"NON-INFERIOR\" if res['is_non_inferior'] else \"NOT NON-INFERIOR\"\n",
    "    observed_rate = variants[name]['x'] / variants[name]['n']\n",
    "    print(f\"Variant {name}: {status}\")\n",
    "    print(f\"  Observed rate: {observed_rate:.2%}, Posterior mean: {res['variant_rate']:.2%}\")\n",
    "    print(f\"  P(variant > threshold): {res['probability']:.2%}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Visualize\n",
    "fig, ax = plot_weakly_informative_prior_with_variants(results_ni)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Takeaway: Same Data, Different Answers\n",
    "\n",
    "| Method | Variant C Result | Actionable? |\n",
    "|--------|-----------------|-------------|\n",
    "| **NHST** | p-value ~ 0.45 (45%), \"fail to reject\" | No |\n",
    "| **Bayesian** | P(non-inferior) > 95% | **Yes** |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Part 5: Select Best Variant\n",
    "\n",
    "## NHST Can't Answer \"Which is Best?\"\n",
    "\n",
    "| Approach | Problem |\n",
    "|---|---|\n",
    "| Highest observed rate | Ignores uncertainty |\n",
    "| Pairwise t-tests + Bonferroni | Very conservative |\n",
    "| ANOVA + post-hoc | Only says \"something differs\" |\n",
    "\n",
    "**None directly answer**: \"What is P(A is best)?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Bayesian: Direct Probability\n",
    "\n",
    "1. Compute **posterior Beta** for each variant\n",
    "2. **Monte Carlo**: draw 100k samples from each\n",
    "3. Count how often each variant wins\n",
    "\n",
    "Result: $P(A \\text{ is best}) = 88\\%$, $P(B) = 3\\%$, $P(C) = 9\\%$\n",
    "\n",
    "No corrections needed. Scales to any number of variants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "from bayesian import select_best_variant\n",
    "from plotting_utils import plot_multiple_posteriors_comparison\n",
    "\n",
    "# Select the best variant using Monte Carlo simulation\n",
    "selection = select_best_variant(\n",
    "    variants_data=variants,\n",
    "    alpha_prior=1,   # Non-informative prior for fair comparison\n",
    "    beta_prior=1,\n",
    "    credible_level=0.95,\n",
    "    n_simulations=100000\n",
    ")\n",
    "\n",
    "# Display results\n",
    "print(\"Probability Each Variant is Best\")\n",
    "print(\"=\" * 50)\n",
    "for name in ['A', 'B', 'C']:\n",
    "    prob = selection['probabilities'][name]\n",
    "    bar = '#' * int(prob * 50)\n",
    "    print(f\"  P({name} is best) = {prob:.2%}  {bar}\")\n",
    "\n",
    "winner = selection['best_variant']\n",
    "print(f\"\\nWinner: Variant {winner}\")\n",
    "print(f\"  Probability of being best: {selection['probabilities'][winner]:.2%}\")\n",
    "print(f\"  Posterior mean: {selection['posterior_means'][winner]:.2%}\")\n",
    "ci = selection['credible_intervals'][winner]\n",
    "print(f\"  95% Credible interval: [{ci[0]:.2%}, {ci[1]:.2%}]\")\n",
    "print(f\"  Expected loss: {selection['expected_loss'][winner]:.4f}\")\n",
    "\n",
    "# Visualize posterior distributions\n",
    "posteriors = {}\n",
    "for name, data in variants.items():\n",
    "    alpha_post = data['x'] + 1\n",
    "    beta_post = data['n'] - data['x'] + 1\n",
    "    posteriors[name] = {\n",
    "        'alpha': alpha_post,\n",
    "        'beta': beta_post,\n",
    "        'mean': alpha_post / (alpha_post + beta_post),\n",
    "        'ci_95': (beta_dist.ppf(0.025, alpha_post, beta_post),\n",
    "                  beta_dist.ppf(0.975, alpha_post, beta_post))\n",
    "    }\n",
    "\n",
    "fig, ax = plot_multiple_posteriors_comparison(\n",
    "    posteriors=posteriors,\n",
    "    control_group_conversion_rate=control_rate,\n",
    "    epsilon=epsilon\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Part 6: The Deployment Bottleneck\n",
    "\n",
    "## Real-World Timeline\n",
    "| Date | Event |\n",
    "|------|-------|\n",
    "| **Oct** | Bug at launch, variant C gets all the traffic, missing control group |\n",
    "| **Early Nov** | Variant A wins with >90% probability â€” we know |\n",
    "| **Mid Nov** | Amazon release freeze (Black Friday) |\n",
    "| **Late Nov** | Release issues, more rollbacks |\n",
    "| **December** | Digital Channel release freeze, holiday delays |\n",
    "| **January** | Winner (variant A) finally ramped up |\n",
    "\n",
    "**~3 months** from \"we know\" to \"users benefit\" and next iterations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Part 7: Thompson Sampling\n",
    "\n",
    "## The Multi-Armed Bandit Problem\n",
    "\n",
    "<div style=\"display: flex; align-items: center; gap: 40px;\">\n",
    "<div style=\"flex: 1;\">\n",
    "\n",
    "**Casino analogy**: K slot machines, unknown payouts, limited budget.\n",
    "\n",
    "| Casino | A/B Testing |\n",
    "|--------|-------------|\n",
    "| Slot machines | Variants |\n",
    "| Pull lever | Show variant |\n",
    "| Payout | User converts |\n",
    "\n",
    "**Dilemma**: Explore (try machines) vs. Exploit (play the best)\n",
    "\n",
    "</div>\n",
    "<div style=\"flex: 0 0 auto; text-align: center;\">\n",
    "<img src=\"images/multi_armed_bandit.jpg\" style=\"max-height: 320px; border-radius: 8px; box-shadow: 0 4px 12px rgba(0,0,0,0.15);\">\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The Algorithm (5 Lines of Logic)\n",
    "\n",
    "For each user:\n",
    "\n",
    "1. **Sample** from each posterior: $\\theta_i \\sim \\text{Beta}(\\alpha_i, \\beta_i)$\n",
    "2. **Choose** variant with highest sample\n",
    "3. **Show** it to the user\n",
    "4. **Observe** conversion (0 or 1)\n",
    "5. **Update** posterior: $\\alpha \\mathrel{+}= r$, $\\beta \\mathrel{+}= (1-r)$\n",
    "\n",
    "**Early**: wide posteriors â†’ exploration\n",
    "**Later**: narrow posteriors â†’ exploitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "# â”‚          The heart of Thompson Sampling â€” 5 lines of logic      â”‚\n",
    "# â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "def thompson_step(alpha, beta, true_rates):\n",
    "    \"\"\"One round of Thompson Sampling for one user.\"\"\"\n",
    "    samples        = {v: np.random.beta(alpha[v], beta[v]) for v in alpha}  # 1. Sample  Î¸áµ¢ ~ Beta(Î±áµ¢, Î²áµ¢)\n",
    "    chosen         = max(samples, key=samples.get)                          # 2. Choose  variant with highest Î¸\n",
    "    r              = int(np.random.random() < true_rates[chosen])           # 3+4. Show â†’ observe r âˆˆ {0, 1}\n",
    "    alpha[chosen] += r                                                       # 5. Update  Î± += r\n",
    "    beta[chosen]  += (1 - r)                                                 # 5. Update  Î² += 1 âˆ’ r\n",
    "    return chosen, r\n",
    "\n",
    "\n",
    "# â”€â”€ Simulation harness â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def run_thompson_sampling(true_rates, n_users):\n",
    "    \"\"\"Run Thompson Sampling over n_users; return traffic, conversions, and history.\"\"\"\n",
    "    variants = list(true_rates.keys())\n",
    "    alpha    = {v: 1 for v in variants}   # Beta(1,1) = uniform prior\n",
    "    beta     = {v: 1 for v in variants}\n",
    "\n",
    "    n_shown, n_conv = {v: 0 for v in variants}, {v: 0 for v in variants}\n",
    "    total_conv = 0\n",
    "    history = {'user': [], **{f'prob_{v}': [] for v in variants}}\n",
    "\n",
    "    for uid in range(n_users):\n",
    "        chosen, r = thompson_step(alpha, beta, true_rates)  # â† the 5 lines above\n",
    "\n",
    "        n_shown[chosen] += 1\n",
    "        n_conv[chosen]  += r\n",
    "        total_conv      += r\n",
    "\n",
    "        if uid % 50 == 0:   # snapshot: P(each variant is best) via Monte Carlo\n",
    "            mc     = 10_000\n",
    "            counts = {v: 0 for v in variants}\n",
    "            for _ in range(mc):\n",
    "                s = {v: np.random.beta(alpha[v], beta[v]) for v in variants}\n",
    "                counts[max(s, key=s.get)] += 1\n",
    "            history['user'].append(uid)\n",
    "            for v in variants:\n",
    "                history[f'prob_{v}'].append(counts[v] / mc)\n",
    "\n",
    "    return n_shown, n_conv, total_conv, history\n",
    "\n",
    "\n",
    "def run_fixed_allocation(true_rates, n_users):\n",
    "    \"\"\"Baseline: rotate through variants in round-robin order.\"\"\"\n",
    "    variants = list(true_rates.keys())\n",
    "    n_shown, n_conv = {v: 0 for v in variants}, {v: 0 for v in variants}\n",
    "    total_conv = 0\n",
    "    for uid in range(n_users):\n",
    "        chosen     = variants[uid % len(variants)]\n",
    "        r          = int(np.random.random() < true_rates[chosen])\n",
    "        n_shown[chosen] += 1\n",
    "        n_conv[chosen]  += r\n",
    "        total_conv      += r\n",
    "    return n_shown, n_conv, total_conv\n",
    "\n",
    "\n",
    "# â”€â”€ Run both strategies â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "np.random.seed(42)\n",
    "true_rates = {'A': 3244 / 4625, 'B': 1433 / 2100, 'C': 1396 / 2022}\n",
    "n_users    = 5000\n",
    "\n",
    "ts_shown, ts_conv, ts_total, ts_history = run_thompson_sampling(true_rates, n_users)\n",
    "fx_shown, fx_conv, fx_total             = run_fixed_allocation(true_rates, n_users)\n",
    "\n",
    "best    = max(true_rates, key=true_rates.get)\n",
    "optimal = n_users * true_rates[best]\n",
    "\n",
    "# â”€â”€ Print comparison â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(\"THOMPSON SAMPLING vs FIXED ALLOCATION\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'':<20s} {'Thompson':>12s} {'Fixed':>12s}\")\n",
    "print(\"-\" * 60)\n",
    "for v in ['A', 'B', 'C']:\n",
    "    print(f\"Variant {v} traffic:    {100 * ts_shown[v] / n_users:10.1f}%  {100 * fx_shown[v] / n_users:10.1f}%\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"Total conversions:  {ts_total:10d}   {fx_total:10d}\")\n",
    "print(f\"Conversion rate:    {100 * ts_total / n_users:10.2f}%  {100 * fx_total / n_users:10.2f}%\")\n",
    "print(f\"Regret:             {optimal - ts_total:10.0f}   {optimal - fx_total:10.0f}\")\n",
    "print(f\"\\nThompson Sampling gained {ts_total - fx_total:.0f} extra conversions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Visualize: P(variant is best) over time\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "ax.plot(ts_history['user'], ts_history['prob_A'], label='P(A is best)', lw=2, color='#2ecc71')\n",
    "ax.plot(ts_history['user'], ts_history['prob_B'], label='P(B is best)', lw=2, color='#e74c3c')\n",
    "ax.plot(ts_history['user'], ts_history['prob_C'], label='P(C is best)', lw=2, color='#3498db')\n",
    "ax.axhline(y=0.95, color='gray', ls='--', lw=1, alpha=0.5, label='95% threshold')\n",
    "ax.set_xlabel('Number of Users', fontsize=12)\n",
    "ax.set_ylabel('Probability of Being Best', fontsize=12)\n",
    "ax.set_title('Thompson Sampling: Learning Which Variant is Best Over Time', fontsize=14, fontweight='bold')\n",
    "ax.legend(loc='right', fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_ylim(0, 1.05)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Find when 95% confidence reached\n",
    "for i, p in enumerate(ts_history['prob_A']):\n",
    "    if p >= 0.95:\n",
    "        print(f\"Reached 95% confidence that A is best after ~{ts_history['user'][i]:,} users\")\n",
    "        break\n",
    "else:\n",
    "    print(f\"Did not reach 95% confidence within {n_users:,} users (but traffic was already optimized)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Key Benefits\n",
    "\n",
    "- **Dynamic traffic allocation** â€” better variants get more traffic automatically\n",
    "- **Add variants anytime** â€” new variants enter with Beta(1,1), compete immediately\n",
    "- **No stopping rules** â€” algorithm keeps improving\n",
    "- **Minimizes regret** â€” fewer users see inferior variants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Production Considerations\n",
    "\n",
    "| Issue | Solution |\n",
    "|---|---|\n",
    "| **Delayed feedback** | Batch updates every 10-60 min |\n",
    "| **Rate drift** | Exponential decay or sliding window |\n",
    "| **Scalability** | $(\\alpha, \\beta)$ in distributed cache |\n",
    "| **Cold start** | Weakly informative priors |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Summary\n",
    "\n",
    "| Step | NHST | Bayesian / Automated |\n",
    "|------|------|---------------------|\n",
    "| Non-inferiority | \"Inconclusive\" | \"95%+ probability\" |\n",
    "| Best variant | Complex corrections | \"A is best at 88%\" |\n",
    "| Deploy winner | Weeks/months | Automatic |\n",
    "| Add variant | Restart test | Add anytime |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bottom Line\n",
    "\n",
    "1. **Bayesian methods** â€” work with small samples, actionable probabilities\n",
    "2. **Thompson Sampling** â€” automates the entire loop, minimizes regret\n",
    "3. **Start simple** â€” Beta-Binomial conjugacy, 5 lines of code\n",
    "\n",
    "### References\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finance",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
