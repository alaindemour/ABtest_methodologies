{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.stats import beta as beta_dist\n",
    "from plotting_utils import plot_gaussian_hypothesis_test\n",
    "from plotting_utils import plot_type_ii_error_analysis, plot_beta_prior_comparison, plot_prior_vs_posterior\n",
    "from plotting_utils import plot_informative_prior_posterior_comparison, plot_weakly_informative_prior_with_variants\n",
    "from plotting_utils import plot_multiple_posteriors_comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<style>\n",
    ".reveal h1 { font-size: 1.8em; color: #4a90d9; }\n",
    ".reveal h2 { font-size: 1.4em; color: #4a90d9; }\n",
    ".reveal h3 { font-size: 1.1em; color: #4a90d9; }\n",
    ".reveal { color: #333; }\n",
    "</style>\n",
    "\n",
    "# From Manual Bayesian A/B Tests to Continuous Thompson Sampling\n",
    "\n",
    "**A  Post Mortem of our Passkeys A/B tests and a proposal automated approaches**\n",
    "\n",
    "<br><br><br><br>\n",
    "\n",
    "<p style=\"font-size: 0.6em; color: #666; line-height: 1.6;\">\n",
    "All the notebooks with running code can be cloned from\n",
    "<br><a href=\"https://github.com/alaindemour/ABtest_methodologies\" style=\"color: #4a90d9;\">https://github.com/alaindemour/ABtest_methodologies</a>\n",
    "<br>Created with the help of Claude Sonnet 4.6\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Presentation Overview\n",
    "\n",
    "1. **Classical vs. Bayesian Statistics**\n",
    "2. **Why Bayesian is Better** for CX / pricing A/B tests\n",
    "3. **Non-Inferiority Test** — NHST fails, Bayesian succeeds\n",
    "4. **Select Best Variant** — direct probability\n",
    "5. **Corporate Iteration Speed** — the deployment bottleneck\n",
    "6. **Thompson Sampling** — the fully automated solution\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#  Business Problem\n",
    "We woudl like to **experiment CX and copy often**, tests **a large number of variants**, get results **within weeks** and **iterate quickly** (e.g. \"fail early\")\n",
    "\n",
    "## Experiment Design Reality\n",
    "Product, engineering, DCE, legal **haggled for months** on design and copy to get their **preferred** ideas in the **only 3** variants we could realitically launch, variants were **already compromises** to fit 3 options, not what we really wanted to test. That a reality of the corporate world for visible UIs.\n",
    " \n",
    "## Real-World Timeline\n",
    "\n",
    "| Date | Event |\n",
    "|------|-------|\n",
    "| **Oct** | bug at launch variant C gets all the traffic , missing control group |\n",
    "| **Early Nov** | Variant A wins with >90% probability -> we know |\n",
    "| **Mid Nov** | Amazon release freeze (Black Friday) |\n",
    "| **Late Nov** | Release issues, more rollbacks |\n",
    "| **December** | Digital Channel release freeze, holiday delays |\n",
    "| **January** | Winner (variant A) finally ramped up |\n",
    "\n",
    "**~3 months** from \"we know\" to \"users benefit\" and next iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Part 1: Classical vs. Bayesian Statistics\n",
    "\n",
    "caveat: once you have millions of data points **none of this matters**, this is when you need to make decisions based on small samples and iterate quickly\n",
    "\n",
    "## The Fundamental Questions\n",
    "\n",
    "Classical statistics a.k.a. Frequentist is using a methodology called Null Hypothesis Signifance Testing (NHST), if you hear **p-values** or **confidence intervals** , **Null Hypothesis** or **this experiment is under powered** it is NHST. Bayesian approaches compute directly precise probabilities for **ALL the possible Hypotheses**, not just a $H_0$.\n",
    "\n",
    "| Framework | Question | Notation |\n",
    "|-----------|----------|----------|\n",
    "| **NHST** | \"How likely is my observation (a.k.a. sample a.k.a data), assuming $H_0$?\" | p(data \\| Hypothesis ) |\n",
    "| **Bayesian** | \"What is the precise probability of all hypotheses, given the observation?\" |p(Hypothesis \\| data) |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## NHST in a Nutshell\n",
    "\n",
    "1. Assume a so called **Null Hypothesis** $H_0$ which is typically what you don't want to be true e.g. **the new drug has no effect** or **the new passkey creation UX degrades conversion**\n",
    "2. Compute a \"test statistic\" from the observed data, in this presentaiton is a mean but can be any statisitcal measure \n",
    "3. If result is \"unlikely enough\" (p-value < 0.05), reject $H_0$\n",
    "\n",
    "### Key Caveats\n",
    "\n",
    "- Rejecting $H_0$ does **not** prove the alternative\n",
    "- The 5% threshold is a **convention**, not a law of nature\n",
    "- No quantified probability of being correct — just \"unlikely\" or \"not unlikely\"\n",
    "- The math involved requires large samples for significance and does not \"compose\" well\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Bayesian in a Nutshell\n",
    "\n",
    "1. Pick a **prior belief** distribution for the measure we are interest in (conventionally noted as $\\theta$ and also called \"the parameter\"), the parameter is how we represent the various hypothesis e.g. $\\theta$ =  convertion rate\n",
    "2. Observe data\n",
    "3. Apply **Bayes' theorem** → get **posterior belief**\n",
    "\n",
    "$$\\boxed{P(\\theta \\mid \\text{data}) = \\frac{P(\\text{data} \\mid \\theta) \\cdot P(\\theta)}{P(\\text{data})}}$$\n",
    "\n",
    "✅ 4. The Posterior belief can become the prior belief for the next update\n",
    "\n",
    "Full probability distribution — compute anything you need at any time during the experiment:\n",
    "point estimates, credible intervals, P(better than threshold), expected values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Useful math for conversion rates : Beta Distribution\n",
    "\n",
    "<div style=\"display: flex; align-items: center; gap: 40px;\">\n",
    "<div style=\"flex: 1;\">\n",
    "\n",
    "- Models a **probability** (values in [0, 1])\n",
    "- Controlled by two parameters α, β\n",
    "- **α − 1** = prior successes, **β − 1** = prior failures\n",
    "- As data accumulates, the distribution **narrows** (more certainty)\n",
    "- Perfect for modeling conversion rates\n",
    "\n",
    "</div>\n",
    "<div style=\"flex: 0 0 auto; text-align: center;\">\n",
    "<img src=\"images/PDF_of_the_Beta_distribution.gif\" style=\"max-height: 320px; border-radius: 8px; box-shadow: 0 4px 12px rgba(0,0,0,0.15);\" alt=\"Beta distribution animation\">\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Bayesian Update: weakly informative prior → posterior after moderate data\n",
    "# Prior: Beta(2, 2) — weakly informative, spread across full [0,1]\n",
    "# Data: 12 successes in 20 trials (60% rate)\n",
    "# Posterior: Beta(14, 10) — shifted toward 0.6 but still broad\n",
    "alpha_prior, beta_prior = 2, 2\n",
    "n_obs, k_obs = 20, 12\n",
    "alpha_post = alpha_prior + k_obs\n",
    "beta_post = beta_prior + (n_obs - k_obs)\n",
    "\n",
    "fig, ax, _, _ = plot_informative_prior_posterior_comparison(\n",
    "    alpha_prior=alpha_prior,\n",
    "    beta_prior=beta_prior,\n",
    "    alpha_posterior=alpha_post,\n",
    "    beta_posterior=beta_post,\n",
    "    x_limits=(0, 1)\n",
    ")\n",
    "print(f\"Prior: Beta({alpha_prior},{beta_prior}) — mean={alpha_prior/(alpha_prior+beta_prior):.0%}\")\n",
    "print(f\"Data: {k_obs} successes in {n_obs} trials\")\n",
    "print(f\"Posterior: Beta({alpha_post},{beta_post}) — mean={alpha_post/(alpha_post+beta_post):.0%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Plot comparison of different Beta prior distributions\n",
    "fig, axes = plot_beta_prior_comparison()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Part 2: Why Bayesian is Better\n",
    "\n",
    "## NHST Problems for Product A/B Tests\n",
    "\n",
    "| Problem | Impact |\n",
    "|---|---|\n",
    "| **Small samples** | At launch, n=150 per variant. NHST: \"inconclusive.\" |\n",
    "| **p-value hacking** | Can't peek at results without inflating false positives |\n",
    "| **Unbalanced samples** | 7,000 control vs. 150 variant — NHST loses power |\n",
    "| **Binary output** | \"Reject\" or \"fail to reject\" — no probabilities |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Where Bayesian Excels\n",
    "\n",
    "| Advantage | Detail |\n",
    "|---|---|\n",
    "| **Small samples** | Prior knowledge + data = meaningful conclusions |\n",
    "| **Unbalanced allocation** | Each variant analyzed independently |\n",
    "| **Many variants** | No multiple comparison penalties |\n",
    "| **Actionable output** | \"47% chance B is best\" — not just reject/fail |\n",
    "| **Continuous monitoring** | Check anytime, no p-hacking concerns |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Fun Fact: FDA Embraces Bayesian (January 2026)\n",
    "\n",
    "> The FDA issued draft guidance: **\"Use of Bayesian Methodology in Clinical Trials of Drugs and Biological Products\"**\n",
    "\n",
    "https://www.fda.gov/regulatory-information/search-fda-guidance-documents/use-bayesian-methodology-clinical-trials-drug-and-biological-products\n",
    "\n",
    "If the most conservative regulator in the world is adopting Bayesian methods, the case for product A/B testing is even stronger.\n",
    "\n",
    "**When does it *not* matter?** Once you have millions of data points and can wait weeks, both approaches converge. The advantage is in the **early, high-uncertainty phase**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Part 3: Non-Inferiority Test\n",
    "\n",
    "## The Setup\n",
    "\n",
    "- Existing flow: **~71% completion rate**\n",
    "- Adding passkey creation (extra pages/clicks)\n",
    "- **Question**: Does the new experience cause unacceptable degradation?\n",
    "- **Non-inferiority margin**: $\\epsilon$ = 2%\n",
    "\n",
    "| Group | Sample size | Conversion rate |\n",
    "|-------|-----------|----------------|\n",
    "| Control | 32,106 | 70.9% |\n",
    "| Variant A | 4,625 | 70.1% |\n",
    "| Variant B | 2,100 | 68.2% |\n",
    "| Variant C | 2,022 | 69.0% |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm, beta as beta_dist\n",
    "\n",
    "# --- Experiment Data ---\n",
    "nC = 32106\n",
    "xC = 22772\n",
    "control_rate = xC / nC\n",
    "\n",
    "variants = {\n",
    "    'A': {'n': 4625, 'x': 3244},\n",
    "    'B': {'n': 2100, 'x': 1433},\n",
    "    'C': {'n': 2022, 'x': 1396}\n",
    "}\n",
    "\n",
    "epsilon = 0.02  # 2% non-inferiority margin\n",
    "\n",
    "print(f\"Control: n={nC:,}, rate={control_rate:.2%}\")\n",
    "for name, d in variants.items():\n",
    "    r = d['x'] / d['n']\n",
    "    print(f\"Variant {name}: n={d['n']:,}, rate={r:.2%}\")\n",
    "print(f\"\\nNon-inferiority margin (epsilon): {epsilon:.0%}\")\n",
    "print(f\"Non-inferiority threshold: {control_rate - epsilon:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## NHST Result: Inconclusive\n",
    "\n",
    "**p-value ~ 0.45** (45%) — very far from the 5% threshold\n",
    "\n",
    "NHST says: \"We can't say anything.\"\n",
    "\n",
    "The test is **severely underpowered** with a sample of n=2,022."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# NHST non-inferiority test on Variant C\n",
    "nX = variants['C']['n']\n",
    "xX = variants['C']['x']\n",
    "hatpC = xC / nC\n",
    "hatpA = xX / nX\n",
    "hatDelta = hatpA - hatpC\n",
    "\n",
    "# Unpooled SE (appropriate for non-inferiority)\n",
    "SE = np.sqrt(hatpC * (1 - hatpC) / nC + hatpA * (1 - hatpA) / nX)\n",
    "mu_H0 = -epsilon\n",
    "\n",
    "# p-value: right tail P(Delta >= observed | H0)\n",
    "p_value = norm.sf(hatDelta, loc=mu_H0, scale=SE)\n",
    "\n",
    "# Power analysis\n",
    "pooled_p = (xC + xX) / (nC + nX)\n",
    "SE_H1 = np.sqrt(pooled_p * (1 - pooled_p) * (1/nC + 1/nX))\n",
    "critical_value = norm.isf(0.05, loc=mu_H0, scale=SE)\n",
    "power = 1 - norm.cdf(critical_value, loc=0, scale=SE_H1)\n",
    "\n",
    "print(\"NHST Non-Inferiority Test (Variant C)\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Observed difference: {hatDelta:.4f}\")\n",
    "print(f\"Standard error: {SE:.4f}\")\n",
    "print(f\"p-value: {p_value:.4f}\")\n",
    "print(f\"Power: {power:.1%}\")\n",
    "print()\n",
    "if p_value <= 0.05:\n",
    "    print(\"Result: REJECT H0 — non-inferiority established\")\n",
    "else:\n",
    "    print(\"Result: FAIL TO REJECT — inconclusive\")\n",
    "    print(f\"  (Power is only {power:.1%} — test is severely underpowered)\")\n",
    "    print(f\"  NHST cannot help us with n={nX} for this variant.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Bayesian: Actionable Answer\n",
    "\n",
    "<!-- **Weakly informative prior** centered on expected performance:\n",
    "\n",
    "$$\\text{Beta}(\\alpha_0, \\beta_0) + \\text{Data} \\Rightarrow \\text{Beta}(\\alpha_0 + k, \\; \\beta_0 + n - k)$$\n",
    "\n",
    "Then directly compute: $P(\\text{variant} > \\text{control} - \\epsilon)$ -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "from bayesian import test_non_inferiority_weakly_informative\n",
    "from plotting_utils import plot_weakly_informative_prior_with_variants\n",
    "\n",
    "# Run Bayesian non-inferiority test on all variants\n",
    "expected_degradation = 0.01  # Domain knowledge: adding clicks may degrade by ~1%\n",
    "\n",
    "results_ni = test_non_inferiority_weakly_informative(\n",
    "    n_control=nC,\n",
    "    x_control=xC,\n",
    "    variants_data=variants,\n",
    "    epsilon=epsilon,\n",
    "    expected_degradation=expected_degradation,\n",
    "    alpha_prior_strength=20,  # Weak prior (high entropy)\n",
    "    threshold=0.95\n",
    ")\n",
    "\n",
    "print(\"Bayesian Non-Inferiority Test Results\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Prior centered at: {control_rate - expected_degradation:.2%}\")\n",
    "print(f\"Test threshold: {control_rate - epsilon:.2%}\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "for name, res in results_ni.items():\n",
    "    status = \"NON-INFERIOR\" if res['is_non_inferior'] else \"NOT NON-INFERIOR\"\n",
    "    observed_rate = variants[name]['x'] / variants[name]['n']\n",
    "    print(f\"Variant {name}: {status}\")\n",
    "    print(f\"  Observed rate: {observed_rate:.2%}, Posterior mean: {res['variant_rate']:.2%}\")\n",
    "    print(f\"  P(variant > threshold): {res['probability']:.2%}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Visualize\n",
    "fig, ax = plot_weakly_informative_prior_with_variants(results_ni)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Takeaway: Same Data, Different Answers\n",
    "\n",
    "| Method | Variant C Result | Actionable? |\n",
    "|--------|-----------------|-------------|\n",
    "| **NHST** | p ~ 0.45, \"fail to reject\" | No |\n",
    "| **Bayesian** | P(non-inferior) > 95% | **Yes** |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Part 4: Select Best Variant\n",
    "\n",
    "## NHST Can't Answer \"Which is Best?\"\n",
    "\n",
    "| Approach | Problem |\n",
    "|---|---|\n",
    "| Highest observed rate | Ignores uncertainty |\n",
    "| Pairwise t-tests + Bonferroni | Very conservative |\n",
    "| ANOVA + post-hoc | Only says \"something differs\" |\n",
    "\n",
    "**None directly answer**: \"What is P(A is best)?\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Bayesian: Direct Probability\n",
    "\n",
    "1. Compute **posterior Beta** for each variant\n",
    "2. **Monte Carlo**: draw 100k samples from each\n",
    "3. Count how often each variant wins\n",
    "\n",
    "Result: $P(A \\text{ is best}) = 88\\%$, $P(B) = 3\\%$, $P(C) = 9\\%$\n",
    "\n",
    "No corrections needed. Scales to any number of variants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "from bayesian import select_best_variant\n",
    "from plotting_utils import plot_multiple_posteriors_comparison\n",
    "\n",
    "# Select the best variant using Monte Carlo simulation\n",
    "selection = select_best_variant(\n",
    "    variants_data=variants,\n",
    "    alpha_prior=1,   # Non-informative prior for fair comparison\n",
    "    beta_prior=1,\n",
    "    credible_level=0.95,\n",
    "    n_simulations=100000\n",
    ")\n",
    "\n",
    "# Display results\n",
    "print(\"Probability Each Variant is Best\")\n",
    "print(\"=\" * 50)\n",
    "for name in ['A', 'B', 'C']:\n",
    "    prob = selection['probabilities'][name]\n",
    "    bar = '#' * int(prob * 50)\n",
    "    print(f\"  P({name} is best) = {prob:.2%}  {bar}\")\n",
    "\n",
    "winner = selection['best_variant']\n",
    "print(f\"\\nWinner: Variant {winner}\")\n",
    "print(f\"  Probability of being best: {selection['probabilities'][winner]:.2%}\")\n",
    "print(f\"  Posterior mean: {selection['posterior_means'][winner]:.2%}\")\n",
    "ci = selection['credible_intervals'][winner]\n",
    "print(f\"  95% Credible interval: [{ci[0]:.2%}, {ci[1]:.2%}]\")\n",
    "print(f\"  Expected loss: {selection['expected_loss'][winner]:.4f}\")\n",
    "\n",
    "# Visualize posterior distributions\n",
    "posteriors = {}\n",
    "for name, data in variants.items():\n",
    "    alpha_post = data['x'] + 1\n",
    "    beta_post = data['n'] - data['x'] + 1\n",
    "    posteriors[name] = {\n",
    "        'alpha': alpha_post,\n",
    "        'beta': beta_post,\n",
    "        'mean': alpha_post / (alpha_post + beta_post),\n",
    "        'ci_95': (beta_dist.ppf(0.025, alpha_post, beta_post),\n",
    "                  beta_dist.ppf(0.975, alpha_post, beta_post))\n",
    "    }\n",
    "\n",
    "fig, ax = plot_multiple_posteriors_comparison(\n",
    "    posteriors=posteriors,\n",
    "    control_group_conversion_rate=control_rate,\n",
    "    epsilon=epsilon\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Part 5: The Deployment Bottleneck\n",
    "\n",
    "## Real-World Timeline\n",
    "\n",
    "| Date | Event |\n",
    "|------|-------|\n",
    "| **Early Nov** | Variant A wins with >88% probability |\n",
    "| **Mid Nov** | Release freeze (Black Friday) |\n",
    "| **Late Nov** | Bug in traffic splitter |\n",
    "| **December** | Legal review + holiday delays |\n",
    "| **January** | Winner finally deployed |\n",
    "\n",
    "**2 months** from \"we know\" to \"users benefit.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The Solution: Automate the Decision Loop\n",
    "\n",
    "**Cost of delay**: 2% better conversion x 10,000 users/day x 60 days = **~12,000 lost conversions**\n",
    "\n",
    "> Instead of: Experiment → Analyze → Decide → Wait → Deploy\n",
    ">\n",
    "> We get: Deploy all variants → **Algorithm optimizes automatically**\n",
    "\n",
    "This is **Thompson Sampling**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Part 6: Thompson Sampling\n",
    "\n",
    "## The Multi-Armed Bandit Problem\n",
    "\n",
    "<div style=\"display: flex; align-items: center; gap: 40px;\">\n",
    "<div style=\"flex: 1;\">\n",
    "\n",
    "**Casino analogy**: K slot machines, unknown payouts, limited budget.\n",
    "\n",
    "| Casino | A/B Testing |\n",
    "|--------|-------------|\n",
    "| Slot machines | Variants |\n",
    "| Pull lever | Show variant |\n",
    "| Payout | User converts |\n",
    "\n",
    "**Dilemma**: Explore (try machines) vs. Exploit (play the best)\n",
    "\n",
    "</div>\n",
    "<div style=\"flex: 0 0 auto; text-align: center;\">\n",
    "<img src=\"images/multi_armed_bandit.jpg\" style=\"max-height: 320px; border-radius: 8px; box-shadow: 0 4px 12px rgba(0,0,0,0.15);\">\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The Algorithm (5 Lines of Logic)\n",
    "\n",
    "For each user:\n",
    "\n",
    "1. **Sample** from each posterior: $\\theta_i \\sim \\text{Beta}(\\alpha_i, \\beta_i)$\n",
    "2. **Choose** variant with highest sample\n",
    "3. **Show** it to the user\n",
    "4. **Observe** conversion (0 or 1)\n",
    "5. **Update** posterior: $\\alpha \\mathrel{+}= r$, $\\beta \\mathrel{+}= (1-r)$\n",
    "\n",
    "**Early**: wide posteriors → exploration\n",
    "**Later**: narrow posteriors → exploitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# --- Thompson Sampling Simulation ---\n",
    "np.random.seed(42)\n",
    "\n",
    "true_rates = {\n",
    "    'A': 3244 / 4625,  # ~70.1%\n",
    "    'B': 1433 / 2100,  # ~68.2%\n",
    "    'C': 1396 / 2022,  # ~69.0%\n",
    "}\n",
    "\n",
    "def run_thompson_sampling(true_rates, n_users):\n",
    "    \"\"\"Simulate Thompson sampling and return results.\"\"\"\n",
    "    variants_list = list(true_rates.keys())\n",
    "    alpha = {v: 1 for v in variants_list}\n",
    "    beta = {v: 1 for v in variants_list}\n",
    "    n_shown = {v: 0 for v in variants_list}\n",
    "    n_conv = {v: 0 for v in variants_list}\n",
    "    total_conv = 0\n",
    "    \n",
    "    history = {'user': [], 'prob_A': [], 'prob_B': [], 'prob_C': []}\n",
    "    \n",
    "    for uid in range(n_users):\n",
    "        samples = {v: np.random.beta(alpha[v], beta[v]) for v in variants_list}\n",
    "        chosen = max(samples, key=samples.get)\n",
    "        converted = int(np.random.random() < true_rates[chosen])\n",
    "        \n",
    "        alpha[chosen] += converted\n",
    "        beta[chosen] += (1 - converted)\n",
    "        n_shown[chosen] += 1\n",
    "        n_conv[chosen] += converted\n",
    "        total_conv += converted\n",
    "        \n",
    "        if uid % 50 == 0:\n",
    "            mc = 10000\n",
    "            counts = {v: 0 for v in variants_list}\n",
    "            for _ in range(mc):\n",
    "                s = {v: np.random.beta(alpha[v], beta[v]) for v in variants_list}\n",
    "                counts[max(s, key=s.get)] += 1\n",
    "            history['user'].append(uid)\n",
    "            for v in variants_list:\n",
    "                history[f'prob_{v}'].append(counts[v] / mc)\n",
    "    \n",
    "    return n_shown, n_conv, total_conv, history\n",
    "\n",
    "def run_fixed_allocation(true_rates, n_users):\n",
    "    \"\"\"Simulate fixed equal allocation.\"\"\"\n",
    "    variants_list = list(true_rates.keys())\n",
    "    n_shown = {v: 0 for v in variants_list}\n",
    "    n_conv = {v: 0 for v in variants_list}\n",
    "    total_conv = 0\n",
    "    for uid in range(n_users):\n",
    "        chosen = variants_list[uid % len(variants_list)]\n",
    "        converted = int(np.random.random() < true_rates[chosen])\n",
    "        n_shown[chosen] += 1\n",
    "        n_conv[chosen] += converted\n",
    "        total_conv += converted\n",
    "    return n_shown, n_conv, total_conv\n",
    "\n",
    "n_users = 5000\n",
    "\n",
    "# Run both strategies\n",
    "ts_shown, ts_conv, ts_total, ts_history = run_thompson_sampling(true_rates, n_users)\n",
    "fx_shown, fx_conv, fx_total = run_fixed_allocation(true_rates, n_users)\n",
    "\n",
    "best = max(true_rates, key=true_rates.get)\n",
    "optimal = n_users * true_rates[best]\n",
    "\n",
    "print(\"THOMPSON SAMPLING vs FIXED ALLOCATION\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'':20s} {'Thompson':>12s} {'Fixed':>12s}\")\n",
    "print(\"-\" * 60)\n",
    "for v in ['A', 'B', 'C']:\n",
    "    ts_pct = 100 * ts_shown[v] / n_users\n",
    "    fx_pct = 100 * fx_shown[v] / n_users\n",
    "    print(f\"Variant {v} traffic:    {ts_pct:10.1f}%  {fx_pct:10.1f}%\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"Total conversions:  {ts_total:10d}   {fx_total:10d}\")\n",
    "print(f\"Conversion rate:    {100*ts_total/n_users:10.2f}%  {100*fx_total/n_users:10.2f}%\")\n",
    "print(f\"Regret:             {optimal - ts_total:10.0f}   {optimal - fx_total:10.0f}\")\n",
    "print(f\"\\nThompson Sampling gained {ts_total - fx_total:.0f} extra conversions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Visualize: P(variant is best) over time\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "ax.plot(ts_history['user'], ts_history['prob_A'], label='P(A is best)', lw=2, color='#2ecc71')\n",
    "ax.plot(ts_history['user'], ts_history['prob_B'], label='P(B is best)', lw=2, color='#e74c3c')\n",
    "ax.plot(ts_history['user'], ts_history['prob_C'], label='P(C is best)', lw=2, color='#3498db')\n",
    "ax.axhline(y=0.95, color='gray', ls='--', lw=1, alpha=0.5, label='95% threshold')\n",
    "ax.set_xlabel('Number of Users', fontsize=12)\n",
    "ax.set_ylabel('Probability of Being Best', fontsize=12)\n",
    "ax.set_title('Thompson Sampling: Learning Which Variant is Best Over Time', fontsize=14, fontweight='bold')\n",
    "ax.legend(loc='right', fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_ylim(0, 1.05)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Find when 95% confidence reached\n",
    "for i, p in enumerate(ts_history['prob_A']):\n",
    "    if p >= 0.95:\n",
    "        print(f\"Reached 95% confidence that A is best after ~{ts_history['user'][i]:,} users\")\n",
    "        break\n",
    "else:\n",
    "    print(f\"Did not reach 95% confidence within {n_users:,} users (but traffic was already optimized)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Key Benefits\n",
    "\n",
    "- **Dynamic traffic allocation** — better variants get more traffic automatically\n",
    "- **Add variants anytime** — new variants enter with Beta(1,1), compete immediately\n",
    "- **No stopping rules** — algorithm keeps improving\n",
    "- **Minimizes regret** — fewer users see inferior variants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Production Considerations\n",
    "\n",
    "| Issue | Solution |\n",
    "|---|---|\n",
    "| **Delayed feedback** | Batch updates every 10-60 min |\n",
    "| **Rate drift** | Exponential decay or sliding window |\n",
    "| **Scalability** | $(\\alpha, \\beta)$ in distributed cache |\n",
    "| **Cold start** | Weakly informative priors |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Summary\n",
    "\n",
    "| Step | NHST | Bayesian / Automated |\n",
    "|------|------|---------------------|\n",
    "| Non-inferiority | \"Inconclusive\" | \"95%+ probability\" |\n",
    "| Best variant | Complex corrections | \"A is best at 88%\" |\n",
    "| Deploy winner | Weeks/months | Automatic |\n",
    "| Add variant | Restart test | Add anytime |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bottom Line\n",
    "\n",
    "1. **Bayesian methods** — work with small samples, actionable probabilities\n",
    "2. **Thompson Sampling** — automates the entire loop, minimizes regret\n",
    "3. **Start simple** — Beta-Binomial conjugacy, 5 lines of code\n",
    "\n",
    "### References\n",
    "\n",
    "Jaynes, *Probability Theory* | Gelman, *Bayesian Data Analysis* | [Russo et al. (2018)](https://arxiv.org/abs/1707.02038) Tutorial on Thompson Sampling | [Ioannidis (2005)](https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124) | [FDA Bayesian Guidance (2026)](https://www.fda.gov/regulatory-information/search-fda-guidance-documents/use-bayesian-methodology-clinical-trials-drugs-and-biological-products) | [Bayesian Methods for Hackers](https://camdavidsonpilon.github.io/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finance",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
