{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e08458a22288",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# From Manual Bayesian A/B Tests to Automated Thompson Sampling\n\n**A practitioner's guide to modern A/B testing for web and mobile product teams**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be91ec109de0",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Presentation Overview\n\n1. **Classical vs. Bayesian Statistics**\n2. **Why Bayesian is Better** for CX / pricing A/B tests\n3. **Non-Inferiority Test** — NHST fails, Bayesian succeeds\n4. **Select Best Variant** — direct probability\n5. **Corporate Iteration Speed** — the deployment bottleneck\n6. **Thompson Sampling** — the fully automated solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e74b821d0a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Part 1: Classical vs. Bayesian Statistics\n\n## The Fundamental Question\n\n| Framework | Question | Notation |\n|-----------|----------|----------|\n| **NHST** | \"How likely is this data, assuming $H_0$?\" | $P(\\text{data} \\mid \\theta)$ |\n| **Bayesian** | \"How likely is the hypothesis, given the data?\" | $P(\\theta \\mid \\text{data})$ |\n\n> **NHST** = smoke detector (binary alarm)\n> **Bayesian** = thermometer (continuous reading)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f3405034f4",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## NHST in a Nutshell\n\n1. Assume $H_0$ (e.g., \"the new experience degrades conversion\")\n2. Compute a test statistic from the data\n3. If result is \"unlikely enough\" (p-value < 0.05), reject $H_0$\n\n### Key Caveats\n\n- Rejecting $H_0$ does **not** prove the alternative\n- The 5% threshold is a **convention**, not a law of nature\n- No probability of being correct — just \"unlikely\" or \"not unlikely\"\n- **Cannot compute expected values** for business decisions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7971b029908f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Bayesian in a Nutshell\n\n1. Pick a **prior** distribution\n2. Observe data\n3. Apply **Bayes' theorem** → get **posterior**\n4. Posterior becomes the prior for the next update\n\n$$\\boxed{P(\\theta \\mid \\text{data}) = \\frac{P(\\text{data} \\mid \\theta) \\cdot P(\\theta)}{P(\\text{data})}}$$\n\nFull probability distribution — compute anything you need:\npoint estimates, credible intervals, P(better than threshold), expected loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c45de9ed9e3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Part 2: Why Bayesian is Better\n\n## NHST Problems for Product A/B Tests\n\n| Problem | Impact |\n|---|---|\n| **Small samples** | At launch, n=150 per variant. NHST: \"inconclusive.\" |\n| **p-value hacking** | Can't peek at results without inflating false positives |\n| **Unbalanced samples** | 7,000 control vs. 150 variant — NHST loses power |\n| **Binary output** | \"Reject\" or \"fail to reject\" — no probabilities |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a76118543fb",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Where Bayesian Excels\n\n| Advantage | Detail |\n|---|---|\n| **Small samples** | Prior knowledge + data = meaningful conclusions |\n| **Unbalanced allocation** | Each variant analyzed independently |\n| **Many variants** | No multiple comparison penalties |\n| **Actionable output** | \"47% chance B is best\" — not just reject/fail |\n| **Continuous monitoring** | Check anytime, no p-hacking concerns |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce170bea0f0",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## FDA Embraces Bayesian (January 2026)\n\n> The FDA issued draft guidance: **\"Use of Bayesian Methodology in Clinical Trials of Drugs and Biological Products\"**\n\nIf the most conservative regulator in the world is adopting Bayesian methods, the case for product A/B testing is even stronger.\n\n**When does it *not* matter?** Once you have millions of data points and can wait weeks, both approaches converge. The advantage is in the **early, high-uncertainty phase**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049ebb50361e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Part 3: Non-Inferiority Test\n\n## The Setup\n\n- Existing flow: **~71% completion rate**\n- Adding passkey creation (extra pages/clicks)\n- **Question**: Does the new experience cause unacceptable degradation?\n- **Non-inferiority margin**: $\\epsilon$ = 2%\n\n| Group | Sample size | Conversion rate |\n|-------|-----------|----------------|\n| Control | 32,106 | 70.9% |\n| Variant A | 4,625 | 70.1% |\n| Variant B | 2,100 | 68.2% |\n| Variant C | 2,022 | 69.0% |"
   ]
  },
  {
   "cell_type": "code",
   "id": "1e10d4ddf231",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "%matplotlib inline\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm, beta as beta_dist\n\n# --- Experiment Data ---\nnC = 32106\nxC = 22772\ncontrol_rate = xC / nC\n\nvariants = {\n    'A': {'n': 4625, 'x': 3244},\n    'B': {'n': 2100, 'x': 1433},\n    'C': {'n': 2022, 'x': 1396}\n}\n\nepsilon = 0.02  # 2% non-inferiority margin\n\nprint(f\"Control: n={nC:,}, rate={control_rate:.2%}\")\nfor name, d in variants.items():\n    r = d['x'] / d['n']\n    print(f\"Variant {name}: n={d['n']:,}, rate={r:.2%}\")\nprint(f\"\\nNon-inferiority margin (epsilon): {epsilon:.0%}\")\nprint(f\"Non-inferiority threshold: {control_rate - epsilon:.2%}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "0c3d883ad289",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## NHST Result: Inconclusive\n\n**p-value ~ 0.45** — far from the 5% threshold\n\nNHST says: \"We can't say anything.\"\n\nThe test is **severely underpowered** with n=2,022."
   ]
  },
  {
   "cell_type": "code",
   "id": "4c39645e475c",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# NHST non-inferiority test on Variant C\nnX = variants['C']['n']\nxX = variants['C']['x']\nhatpC = xC / nC\nhatpA = xX / nX\nhatDelta = hatpA - hatpC\n\n# Unpooled SE (appropriate for non-inferiority)\nSE = np.sqrt(hatpC * (1 - hatpC) / nC + hatpA * (1 - hatpA) / nX)\nmu_H0 = -epsilon\n\n# p-value: right tail P(Delta >= observed | H0)\np_value = norm.sf(hatDelta, loc=mu_H0, scale=SE)\n\n# Power analysis\npooled_p = (xC + xX) / (nC + nX)\nSE_H1 = np.sqrt(pooled_p * (1 - pooled_p) * (1/nC + 1/nX))\ncritical_value = norm.isf(0.05, loc=mu_H0, scale=SE)\npower = 1 - norm.cdf(critical_value, loc=0, scale=SE_H1)\n\nprint(\"NHST Non-Inferiority Test (Variant C)\")\nprint(\"=\" * 50)\nprint(f\"Observed difference: {hatDelta:.4f}\")\nprint(f\"Standard error: {SE:.4f}\")\nprint(f\"p-value: {p_value:.4f}\")\nprint(f\"Power: {power:.1%}\")\nprint()\nif p_value <= 0.05:\n    print(\"Result: REJECT H0 — non-inferiority established\")\nelse:\n    print(\"Result: FAIL TO REJECT — inconclusive\")\n    print(f\"  (Power is only {power:.1%} — test is severely underpowered)\")\n    print(f\"  NHST cannot help us with n={nX} for this variant.\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "0b61ee2e8dbf",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Bayesian: Actionable Answer\n\n**Weakly informative prior** centered on expected performance:\n\n$$\\text{Beta}(\\alpha_0, \\beta_0) + \\text{Data} \\Rightarrow \\text{Beta}(\\alpha_0 + k, \\; \\beta_0 + n - k)$$\n\nThen directly compute: $P(\\text{variant} > \\text{control} - \\epsilon)$"
   ]
  },
  {
   "cell_type": "code",
   "id": "292c6b1209c6",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "from bayesian import test_non_inferiority_weakly_informative\nfrom plotting_utils import plot_weakly_informative_prior_with_variants\n\n# Run Bayesian non-inferiority test on all variants\nexpected_degradation = 0.01  # Domain knowledge: adding clicks may degrade by ~1%\n\nresults_ni = test_non_inferiority_weakly_informative(\n    n_control=nC,\n    x_control=xC,\n    variants_data=variants,\n    epsilon=epsilon,\n    expected_degradation=expected_degradation,\n    alpha_prior_strength=20,  # Weak prior (high entropy)\n    threshold=0.95\n)\n\nprint(\"Bayesian Non-Inferiority Test Results\")\nprint(\"=\" * 60)\nprint(f\"Prior centered at: {control_rate - expected_degradation:.2%}\")\nprint(f\"Test threshold: {control_rate - epsilon:.2%}\")\nprint()\n\nfor name, res in results_ni.items():\n    status = \"NON-INFERIOR\" if res['is_non_inferior'] else \"NOT NON-INFERIOR\"\n    observed_rate = variants[name]['x'] / variants[name]['n']\n    print(f\"Variant {name}: {status}\")\n    print(f\"  Observed rate: {observed_rate:.2%}, Posterior mean: {res['variant_rate']:.2%}\")\n    print(f\"  P(variant > threshold): {res['probability']:.2%}\")\n    print()\n\n# Visualize\nfig, ax = plot_weakly_informative_prior_with_variants(results_ni)\nplt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "8e1dd56993b1",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Takeaway: Same Data, Different Answers\n\n| Method | Variant C Result | Actionable? |\n|--------|-----------------|-------------|\n| **NHST** | p ~ 0.45, \"fail to reject\" | No |\n| **Bayesian** | P(non-inferior) > 95% | **Yes** |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b06318e30e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Part 4: Select Best Variant\n\n## NHST Can't Answer \"Which is Best?\"\n\n| Approach | Problem |\n|---|---|\n| Highest observed rate | Ignores uncertainty |\n| Pairwise t-tests + Bonferroni | Very conservative |\n| ANOVA + post-hoc | Only says \"something differs\" |\n\n**None directly answer**: \"What is P(A is best)?\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144b89bc4365",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Bayesian: Direct Probability\n\n1. Compute **posterior Beta** for each variant\n2. **Monte Carlo**: draw 100k samples from each\n3. Count how often each variant wins\n\nResult: $P(A \\text{ is best}) = 88\\%$, $P(B) = 3\\%$, $P(C) = 9\\%$\n\nNo corrections needed. Scales to any number of variants."
   ]
  },
  {
   "cell_type": "code",
   "id": "baf1babee45f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "from bayesian import select_best_variant\nfrom plotting_utils import plot_multiple_posteriors_comparison\n\n# Select the best variant using Monte Carlo simulation\nselection = select_best_variant(\n    variants_data=variants,\n    alpha_prior=1,   # Non-informative prior for fair comparison\n    beta_prior=1,\n    credible_level=0.95,\n    n_simulations=100000\n)\n\n# Display results\nprint(\"Probability Each Variant is Best\")\nprint(\"=\" * 50)\nfor name in ['A', 'B', 'C']:\n    prob = selection['probabilities'][name]\n    bar = '#' * int(prob * 50)\n    print(f\"  P({name} is best) = {prob:.2%}  {bar}\")\n\nwinner = selection['best_variant']\nprint(f\"\\nWinner: Variant {winner}\")\nprint(f\"  Probability of being best: {selection['probabilities'][winner]:.2%}\")\nprint(f\"  Posterior mean: {selection['posterior_means'][winner]:.2%}\")\nci = selection['credible_intervals'][winner]\nprint(f\"  95% Credible interval: [{ci[0]:.2%}, {ci[1]:.2%}]\")\nprint(f\"  Expected loss: {selection['expected_loss'][winner]:.4f}\")\n\n# Visualize posterior distributions\nposteriors = {}\nfor name, data in variants.items():\n    alpha_post = data['x'] + 1\n    beta_post = data['n'] - data['x'] + 1\n    posteriors[name] = {\n        'alpha': alpha_post,\n        'beta': beta_post,\n        'mean': alpha_post / (alpha_post + beta_post),\n        'ci_95': (beta_dist.ppf(0.025, alpha_post, beta_post),\n                  beta_dist.ppf(0.975, alpha_post, beta_post))\n    }\n\nfig, ax = plot_multiple_posteriors_comparison(\n    posteriors=posteriors,\n    control_group_conversion_rate=control_rate,\n    epsilon=epsilon\n)\nplt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "42f0e69edcd1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Part 5: The Deployment Bottleneck\n\n## Real-World Timeline\n\n| Date | Event |\n|------|-------|\n| **Early Nov** | Variant A wins with >88% probability |\n| **Mid Nov** | Release freeze (Black Friday) |\n| **Late Nov** | Bug in traffic splitter |\n| **December** | Legal review + holiday delays |\n| **January** | Winner finally deployed |\n\n**2 months** from \"we know\" to \"users benefit.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f3ed5b5c57",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The Solution: Automate the Decision Loop\n\n**Cost of delay**: 2% better conversion x 10,000 users/day x 60 days = **~12,000 lost conversions**\n\n> Instead of: Experiment → Analyze → Decide → Wait → Deploy\n>\n> We get: Deploy all variants → **Algorithm optimizes automatically**\n\nThis is **Thompson Sampling**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733bdf20a1fb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Part 6: Thompson Sampling\n\n## The Multi-Armed Bandit Problem\n\n**Casino analogy**: K slot machines, unknown payouts, limited budget.\n\n| Casino | A/B Testing |\n|--------|-------------|\n| Slot machines | Variants |\n| Pull lever | Show variant |\n| Payout | User converts |\n\n**Dilemma**: Explore (try machines) vs. Exploit (play the best)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5534479d2054",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The Algorithm (5 Lines of Logic)\n\nFor each user:\n\n1. **Sample** from each posterior: $\\theta_i \\sim \\text{Beta}(\\alpha_i, \\beta_i)$\n2. **Choose** variant with highest sample\n3. **Show** it to the user\n4. **Observe** conversion (0 or 1)\n5. **Update** posterior: $\\alpha \\mathrel{+}= r$, $\\beta \\mathrel{+}= (1-r)$\n\n**Early**: wide posteriors → exploration\n**Later**: narrow posteriors → exploitation"
   ]
  },
  {
   "cell_type": "code",
   "id": "76fe87da60a5",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# --- Thompson Sampling Simulation ---\nnp.random.seed(42)\n\ntrue_rates = {\n    'A': 3244 / 4625,  # ~70.1%\n    'B': 1433 / 2100,  # ~68.2%\n    'C': 1396 / 2022,  # ~69.0%\n}\n\ndef run_thompson_sampling(true_rates, n_users):\n    \"\"\"Simulate Thompson sampling and return results.\"\"\"\n    variants_list = list(true_rates.keys())\n    alpha = {v: 1 for v in variants_list}\n    beta = {v: 1 for v in variants_list}\n    n_shown = {v: 0 for v in variants_list}\n    n_conv = {v: 0 for v in variants_list}\n    total_conv = 0\n    \n    history = {'user': [], 'prob_A': [], 'prob_B': [], 'prob_C': []}\n    \n    for uid in range(n_users):\n        samples = {v: np.random.beta(alpha[v], beta[v]) for v in variants_list}\n        chosen = max(samples, key=samples.get)\n        converted = int(np.random.random() < true_rates[chosen])\n        \n        alpha[chosen] += converted\n        beta[chosen] += (1 - converted)\n        n_shown[chosen] += 1\n        n_conv[chosen] += converted\n        total_conv += converted\n        \n        if uid % 50 == 0:\n            mc = 10000\n            counts = {v: 0 for v in variants_list}\n            for _ in range(mc):\n                s = {v: np.random.beta(alpha[v], beta[v]) for v in variants_list}\n                counts[max(s, key=s.get)] += 1\n            history['user'].append(uid)\n            for v in variants_list:\n                history[f'prob_{v}'].append(counts[v] / mc)\n    \n    return n_shown, n_conv, total_conv, history\n\ndef run_fixed_allocation(true_rates, n_users):\n    \"\"\"Simulate fixed equal allocation.\"\"\"\n    variants_list = list(true_rates.keys())\n    n_shown = {v: 0 for v in variants_list}\n    n_conv = {v: 0 for v in variants_list}\n    total_conv = 0\n    for uid in range(n_users):\n        chosen = variants_list[uid % len(variants_list)]\n        converted = int(np.random.random() < true_rates[chosen])\n        n_shown[chosen] += 1\n        n_conv[chosen] += converted\n        total_conv += converted\n    return n_shown, n_conv, total_conv\n\nn_users = 5000\n\n# Run both strategies\nts_shown, ts_conv, ts_total, ts_history = run_thompson_sampling(true_rates, n_users)\nfx_shown, fx_conv, fx_total = run_fixed_allocation(true_rates, n_users)\n\nbest = max(true_rates, key=true_rates.get)\noptimal = n_users * true_rates[best]\n\nprint(\"THOMPSON SAMPLING vs FIXED ALLOCATION\")\nprint(\"=\" * 60)\nprint(f\"{'':20s} {'Thompson':>12s} {'Fixed':>12s}\")\nprint(\"-\" * 60)\nfor v in ['A', 'B', 'C']:\n    ts_pct = 100 * ts_shown[v] / n_users\n    fx_pct = 100 * fx_shown[v] / n_users\n    print(f\"Variant {v} traffic:    {ts_pct:10.1f}%  {fx_pct:10.1f}%\")\nprint(\"-\" * 60)\nprint(f\"Total conversions:  {ts_total:10d}   {fx_total:10d}\")\nprint(f\"Conversion rate:    {100*ts_total/n_users:10.2f}%  {100*fx_total/n_users:10.2f}%\")\nprint(f\"Regret:             {optimal - ts_total:10.0f}   {optimal - fx_total:10.0f}\")\nprint(f\"\\nThompson Sampling gained {ts_total - fx_total:.0f} extra conversions\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "7c93fd6c9d76",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Visualize: P(variant is best) over time\nfig, ax = plt.subplots(figsize=(12, 5))\nax.plot(ts_history['user'], ts_history['prob_A'], label='P(A is best)', lw=2, color='#2ecc71')\nax.plot(ts_history['user'], ts_history['prob_B'], label='P(B is best)', lw=2, color='#e74c3c')\nax.plot(ts_history['user'], ts_history['prob_C'], label='P(C is best)', lw=2, color='#3498db')\nax.axhline(y=0.95, color='gray', ls='--', lw=1, alpha=0.5, label='95% threshold')\nax.set_xlabel('Number of Users', fontsize=12)\nax.set_ylabel('Probability of Being Best', fontsize=12)\nax.set_title('Thompson Sampling: Learning Which Variant is Best Over Time', fontsize=14, fontweight='bold')\nax.legend(loc='right', fontsize=10)\nax.grid(True, alpha=0.3)\nax.set_ylim(0, 1.05)\nplt.tight_layout()\nplt.show()\n\n# Find when 95% confidence reached\nfor i, p in enumerate(ts_history['prob_A']):\n    if p >= 0.95:\n        print(f\"Reached 95% confidence that A is best after ~{ts_history['user'][i]:,} users\")\n        break\nelse:\n    print(f\"Did not reach 95% confidence within {n_users:,} users (but traffic was already optimized)\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "09cb9b734168",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Key Benefits\n\n- **Dynamic traffic allocation** — better variants get more traffic automatically\n- **Add variants anytime** — new variants enter with Beta(1,1), compete immediately\n- **No stopping rules** — algorithm keeps improving\n- **Minimizes regret** — fewer users see inferior variants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e32ecbd157d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Production Considerations\n\n| Issue | Solution |\n|---|---|\n| **Delayed feedback** | Batch updates every 10-60 min |\n| **Rate drift** | Exponential decay or sliding window |\n| **Scalability** | $(\\alpha, \\beta)$ in distributed cache |\n| **Cold start** | Weakly informative priors |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787473162dbf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Summary\n\n| Step | NHST | Bayesian / Automated |\n|------|------|---------------------|\n| Non-inferiority | \"Inconclusive\" | \"95%+ probability\" |\n| Best variant | Complex corrections | \"A is best at 88%\" |\n| Deploy winner | Weeks/months | Automatic |\n| Add variant | Restart test | Add anytime |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966d51287e33",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Bottom Line\n\n1. **Bayesian methods** — work with small samples, actionable probabilities\n2. **Thompson Sampling** — automates the entire loop, minimizes regret\n3. **Start simple** — Beta-Binomial conjugacy, 5 lines of code\n\n### References\n\nJaynes, *Probability Theory* | Gelman, *Bayesian Data Analysis* | [Russo et al. (2018)](https://arxiv.org/abs/1707.02038) Tutorial on Thompson Sampling | [Ioannidis (2005)](https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124) | [FDA Bayesian Guidance (2026)](https://www.fda.gov/regulatory-information/search-fda-guidance-documents/use-bayesian-methodology-clinical-trials-drugs-and-biological-products) | [Bayesian Methods for Hackers](https://camdavidsonpilon.github.io/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}